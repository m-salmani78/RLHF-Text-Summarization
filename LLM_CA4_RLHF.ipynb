{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9AWeWaSliGs"
      },
      "source": [
        "## CA 4, LLMs Spring 2024\n",
        "\n",
        "- **Name:** Mohammad Mahdi Salmani\n",
        "- **Student ID:** 810102174\n",
        "\n",
        "---\n",
        "### This is due on **14 June**, submitted via [elearn](https://elearn.ut.ac.ir/).\n",
        "#### Your submission should be named using the following format: `CA4_LASTNAME_STUDENTID.ipynb`.\n",
        "\n",
        "---\n",
        "\n",
        "##### *How to do this problem set:*\n",
        "\n",
        "- Some questions require writing Python code and computing results, and the rest of them have written answers. For coding problems, you will have to fill out all code blocks that say `WRITE YOUR CODE HERE`.\n",
        "\n",
        "- For text-based answers, you should replace the text that says \"Write your answer here...\" with your actual answer.\n",
        "\n",
        "- There is no penalty for using AI assistance on this homework as long as you fully disclose it in the final cell of this notebook (this includes storing any prompts that you feed to large language models). That said, anyone caught using AI assistance without proper disclosure will receive a zero on the assignment (we have several automatic tools to detect such cases). We're literally allowing you to use it with no limitations, so there is no reason to lie!\n",
        "\n",
        "---\n",
        "\n",
        "##### *Academic honesty*\n",
        "\n",
        "- We will audit the Colab notebooks from a set number of students, chosen at random. The audits will check that the code you wrote actually generates the answers in your notebook. If you turn in correct answers on your notebook without code that actually generates those answers, we will consider this a serious case of cheating.\n",
        "\n",
        "- We will also run automatic checks of Colab notebooks for plagiarism. Copying code from others is also considered a serious case of cheating.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqjNIhG0liGv"
      },
      "source": [
        "# RLHF (55 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTo0AfIPliGv"
      },
      "source": [
        "## Introduction to RLHF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOQLOhnMliGv"
      },
      "source": [
        "<img src=\"https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/08/31/ML-14874_image001.jpg\"/>\n",
        "</div>\n",
        "\n",
        "With the recent public introduction of ChatGPT, reinforcement learning from human feedback (RLHF) has become a hot topic in language modeling circles -- both academic and industrial.\n",
        "We can trace the application of RLHF to natural language processing OpenAI's 2019 release of <br>[Fine-Tuning Language Models from Human Preferences](https://arxiv.org/abs/1909.08593).\n",
        "\n",
        "Fast forward one year when OpenAI released one of its first significant papers on reinforcement learning from human feedback applied to natural language generation.\n",
        "\n",
        "In that paper-<br>[Learning to summarize from human feedback](https://arxiv.org/abs/2009.01325)-OpenAI showed that simply fine-tuning on summarization data leads to suboptimal performance when evaluated on human preferences. The authors suggest optimizing for human preferences directly via a reinforcement learning approach to alleviate these performance issues.\n",
        "\n",
        "\n",
        "**Learn More:**\n",
        "<br>[Huggingface Deep Reinforcement Learning Course](https://huggingface.co/learn/deep-rl-course/en/unit0/introduction)\n",
        "<br>[Research Papers for Reinforcement Learning with Human Feedback ](https://github.com/opendilab/awesome-RLHF)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWJejByfliGv"
      },
      "source": [
        "## Import Libraries and Set Constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zIqcvJY4liGv"
      },
      "outputs": [],
      "source": [
        "%pip install datasets\n",
        "%pip install evaluate\n",
        "%pip install rouge_score\n",
        "%pip install accelerate -U\n",
        "%pip install transformers[torch]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "K0uv-c3HliGw"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "import random\n",
        "import evaluate\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from datasets import load_dataset\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import transformers\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer, get_scheduler\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    default_data_collator,\n",
        ")\n",
        "from transformers import AdamW\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177,
          "referenced_widgets": [
            "e400bbe893d744b4bc4ec3c00d0ab49a",
            "57be34f94b554f0e94f45635efd721b7",
            "04588e43dc174ae5bcebc0ef01d581dc",
            "bd1e9d756633421e980ac84a1ed3df96",
            "ed839cf80d8e4f4a8feaa109cd9202b6",
            "7cf3fe343cdd45b291523b15dc8f4c1a",
            "ac236fc0d5bc4d8f962e3d35b859893d",
            "58cabc7c155747fc8cbe2f27f1beb289",
            "cce757f48382449da0d3e3bf87272284",
            "99d0e034709c40359095a9004cc46798",
            "e6953b8a8ace427ca7689f7fc6cfd6b3",
            "a22888ab49b941bfae153b1d7d6a3fe9",
            "054c5f4fc64744a7a46e991855c7b386",
            "caaca6163cff4afb9b28978b1e64065a",
            "896bed8372804158aa4bc944e6401f42",
            "40465bc3852f40018eb5173d2a789c7f",
            "d18ab3331f1a42f1af89aca50b9e78e6",
            "08a9f29c73b54e0cbc89738191edb1a8",
            "12ce1164d18249b3807e5ec45aac4a84",
            "1f99bdeb99dc43f882494cb9a8d1f664",
            "41f16b59ab674b67ab1577adb413ae48",
            "1dd9d180974942d89cabcc4d318a6cf0",
            "b41bb97a0a7a4cd589d837144eed8200",
            "5446c6060f8e419ab8184d0e15981690",
            "236c712f6f234e3f8d7f4ea00feb7f6a",
            "7b770a26b25c449fbdac9824c6b00204",
            "30ae280e5d5b462daa1f61b929e51a3e",
            "a97ec2a948e549ae9d97c2ce6d8d962e",
            "b2729e2fde2549d1b531e9320dd6649d",
            "e8bd37b87fba4f8a9e2d0e9bb80a13f0",
            "748e4fce751841348c8907d56a01d2a1",
            "8cc35a3254b049de9d1535e4c4a64dda",
            "5835fb83bd014edcaedc1974e2738273",
            "7cd8e757c96f4a4481c5fffd99fb2cf2",
            "c5541f7a0b3d405388df008eb820a130",
            "ca480988b2404679954759cb9e2c991c",
            "f73da3dc44384c7baad205eaa14bfb41",
            "af155570f61742c181961e49703cf911",
            "9b3cc7be38ab486abb29f68c4ec58388",
            "5e9e490c3c244b09a1d8f9007a5d8717",
            "97816036a7c643feb7c24755f4e2233b",
            "8ee845415acf4bb29a6a3fc5c2c72070",
            "41afb58c5a964028a4943def4b861b97",
            "55634652e74049b199344e325dff5676",
            "dfc95e5b17b94e1dae5b0c5a26a9da5d",
            "7bcdb14ff8c64ff4b1d7b882a85f89dd",
            "2e3fa17580e544aaa238a07cdeb116b7",
            "723a0a0fae6344b2bdc445d69af1517a",
            "29c0f9d47313413386f284f7393211d1",
            "005b8f782bdb4ab2a8a5e40a75674d96",
            "5c38c56a72d74118a65c7eca2d47aaa0",
            "af5827003e7c43d8b6bda1efceeb1fae",
            "5d82735ec2df45c7b9fd820df07d938d",
            "c16c6f1424134cb7ab354757b7ce2c15",
            "0b831cc698eb4838960af0add2becea1"
          ]
        },
        "id": "dwFPQ6UFliGw",
        "outputId": "105e42f6-831e-42a5-e6f9-39d11c7daf9c"
      },
      "outputs": [],
      "source": [
        "class CONFIG:\n",
        "    seed = 42\n",
        "    max_len = 550\n",
        "    train_batch_size = 16\n",
        "    eval_batch_size = 1\n",
        "    eval_steps = 500\n",
        "    epochs = 5\n",
        "    save_steps = 1000\n",
        "    learning_rate = 1e-4\n",
        "    gradient_accumulation_steps = 1\n",
        "    model_name = 'gpt2'\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "    output_dir = \"gpt2-supervised-summarize-checkpoint\"\n",
        "    output_dir_rm = \"rm_checkpoint\"\n",
        "\n",
        "device = CONFIG.device\n",
        "rw_device = CONFIG.device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snknIeG6liGw"
      },
      "source": [
        "## Implementing Learning for Summarization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBOWhTBJliGx"
      },
      "source": [
        " In this notebook by using trlX, we will implement RLHF for a summarization task. The training process consists of three parts:\n",
        "\n",
        "*   We will first fine-tune a pre-trained transformer model on our summarization dataset. This is our supervised fine-tuned model (SFT).\n",
        "* We will then train a reward model (RM). This model is initialized from the SFT model and outputs a scalar value. This scalar value is the reward that indicates the preferability of a summary.  \n",
        "\n",
        "*   Finally, we use the RM to fine-tune the SFT model via PPO. This step aligns our SFT model with human preference."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXsS0ZcgliGx"
      },
      "source": [
        "## Section One: Supervised Fine Tuning (5 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66TUpjRyliGx"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJ1IjMDQliGx"
      },
      "source": [
        "For our experiment, we'll use the **TLDR summarization** dataset used originally in Learning to summarize from human feedback.\n",
        "\n",
        "Based on that training process described above, we'll need two types of datasets:\n",
        "\n",
        "*   One for fine-tuning the pre-trained supervised model and then for fine-tuning it again with PPO and reward model, and\n",
        "*   One for training our reward model.\n",
        "\n",
        "In our case, the dataset for fine-tuning is the filtered* TLDR dataset. The dataset for training our reward model is the **comparison or preference dataset**.\n",
        "\n",
        "**Note:** I set the number of training examples to 6000, you can increase it, also you can adjust the number of validation examples.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "yJJ6gvoKliGx"
      },
      "outputs": [],
      "source": [
        "tlrdataset_path = \"CarperAI/openai_summarize_tldr\"\n",
        "comparissions_path = \"CarperAI/openai_summarize_comparisons\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yI8w7wuliGx"
      },
      "source": [
        "#### Create Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "lJW3S1KpliGx"
      },
      "outputs": [],
      "source": [
        "class TLDRDataset(Dataset):\n",
        "    def __init__(self, path, tokenizer, split, max_length=CONFIG.max_len):\n",
        "        self.post_list = []\n",
        "        dataset = load_dataset(path, split=split)\n",
        "        for sample in dataset:\n",
        "            self.post_list.append(sample[\"prompt\"] + sample[\"label\"])\n",
        "\n",
        "        if \"train\" in split:\n",
        "          self.post_list = random.sample(self.post_list, min(6000, len(self.post_list)))\n",
        "        elif \"valid\" in split:\n",
        "            self.post_list = self.post_list[0:2000]\n",
        "\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "        self.input_ids = []\n",
        "        self.attn_masks = []\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.post_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        txt = self.post_list[idx]\n",
        "        encodings_dict = self.tokenizer(txt, truncation=True, max_length=self.max_length, padding=\"max_length\")\n",
        "        input_ids = torch.tensor(encodings_dict[\"input_ids\"])\n",
        "        attn_masks = torch.tensor(encodings_dict[\"attention_mask\"])\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": input_ids,\n",
        "            \"attention_mask\": attn_masks,\n",
        "            \"labels\": input_ids,\n",
        "        }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjxXIrRyliGx"
      },
      "source": [
        "#### Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241,
          "referenced_widgets": [
            "caa2f6b29a0349aa80d773185181056b",
            "8d354fed57014964962451731bb319ef",
            "0faf1d3472974ceca6eeda7e9d5f7906",
            "b54c45a49eb1484194a576d0421c0fe0",
            "2bb6760048f24cb59f6ff5f16b3c7acd",
            "93c404b763094295aa1bbcdc5847e3b9",
            "2c3ffd876324474594f95fe1c71d3782",
            "c6c5a944a23e456ebb6c69805e4d4e2e",
            "196db38e52bf47e0a529d725ad71d007",
            "a483b3f8216d4de88866cb1a017c14bb",
            "3451ffe86a4a4d7a8858e4e720789857",
            "5d1aaf2a41fd47e1ba3a2a73855db66b",
            "4a9bad66b87348589618e074a6b2f747",
            "94712aabc9504ec7a3d204a914118b6c",
            "70010175a0c9460c89a2297895f9425e",
            "9cf51736a40e490ba9daa0aa4585d614",
            "5cef8de414a447ff911632ff05beedfb",
            "39e1e4fa159044ea97c5f9c78ba14a1c",
            "45a46219b04b4d5989b5a7a241c165b5",
            "a5c0c29181fc4821b4017e7028372431",
            "f61f3b244ab5421e8a2c18d37c33e290",
            "920ac1c6300d4ac2b826fa0fcc1c4cd8",
            "458e2312cf2c47fea736fc230083a0de",
            "83f9dbdfcf7443ce8589e0c59116afcf",
            "9ed93d180d26497596cdeb3f8d014e09",
            "9544135d58ee491191ea3b16bf2424eb",
            "2510e83f724343019d01a35a84e76bf9",
            "c8cc0f0cf5d14e83b002ead2a0c3afa4",
            "de3fe2d2e22547e1beb6c76b59d71082",
            "d1fe338ae4604838b403b255a4637154",
            "5243aeab7e624b02b273463fb32fbf42",
            "90066549c0b4446bbae7b2a16fbe1a6b",
            "18439c99c16d4162b8a2a52d86dc5847",
            "b6fa7a2add97484cbea0c26ed46d29e6",
            "44e178a0be524daa95b256d5bff31202",
            "c33b7e89df304f78b3b498a8f9c68383",
            "ac756657854e4ec78993df53314cc18f",
            "2923856e65fd40718b7358bfbb3143cf",
            "452cea6360ce498c85e843e348deb1f4",
            "16f10c9d3be140829e228ad4b3aa7705",
            "bda44f920ef0452991f345ffb8843f73",
            "890cde66805f46b2bcc713df00dfbe22",
            "ed16f76131904795900803fb1238f73d",
            "334a2eeec579455ba662deabd578f29d",
            "d3fccbdf94bc44cdb552e3ac37a54e0f",
            "ddcd794463174f51b09f6b77ab732b94",
            "4759413c86e845d9a8e374ee135ff414",
            "38b91d003fc541908101453b9655abb2",
            "7d3ece0ec61a4f7eb21808f759df7690",
            "29201ca978c5470aa05877d0ace36f31",
            "7151d446f6964946af694275001a8b50",
            "ab0a3df7a8904389904bfcb31a148b7f",
            "c692217a3ef84e04bccb3bcdd4a2ec8a",
            "d6ba35709a0f4221bff3209b66f6ccde",
            "64f0e8ad62e448f9b767515e44bf4e9b",
            "329fab4cb7a14053b47bdd56ad38ec60",
            "d839e15480684df99f1ce3a7c6c41342",
            "774a79f0517a4d5c8b2a037f6a59dc3e",
            "7b52f480da1e4554a39b731269dc5d28",
            "96762776b2564b0ca0eda807d998d097",
            "d7554a7bb8bd4d5dbbc03268dc2d77c4",
            "cf4a4ec0a7124457a68d70970889b744",
            "4929031e60fa4ad883215fc9470113ae",
            "a6bc156f830b4829b35f298ed7d733bf",
            "6e2efc4590694d2ab3e02f4baa2ed821",
            "de83309c1bd54e66a613b755a89f4455",
            "5d88dfa6c6e04cc689bdc9f753fd26fa",
            "bb4c6b6b74824b6b8fcc74009aa36768",
            "c6acfb70629745729fa440a02b5aa6f1",
            "d4c3590ed00243a99495add140c2f504",
            "4b02a2cb6fe14ccd9d85a86994c6cb67",
            "a4d54d72871743a68f60983a3bdbf55d",
            "0e017c1b69fe4e89b3a5e169c9387445",
            "5dd2682ec2ab4a1ba0d0023ffe3cc4a9",
            "4a452ec981ff415680f80c2cfd30a0ad",
            "e53325f28cab44a5ab6a9218764b45d2",
            "d5f193695fde47e8b9edd4f84f2ecf2b"
          ]
        },
        "id": "KcTIsUmfliGx",
        "outputId": "6b2d1543-b17d-442c-fabf-37b228ff4e23"
      },
      "outputs": [],
      "source": [
        "train_dataset = TLDRDataset(\n",
        "  path=tlrdataset_path,\n",
        "  tokenizer=CONFIG.tokenizer,\n",
        "  split=\"train\")\n",
        "\n",
        "dev_dataset = TLDRDataset(\n",
        "  path=tlrdataset_path,\n",
        "  tokenizer=CONFIG.tokenizer,\n",
        "  split=\"valid\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGyPTscSliGx"
      },
      "source": [
        "### Load Model and Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "ff6e07c2c9de408cb353b2b57ad52673",
            "8525e5dc75cb42d790ee5e59c96cee5f",
            "f10cd68089cc4e3ebe9b774054517c80",
            "27fa70cf544147f29b2a8a17c4f2faa3",
            "fe88b66639f64622adda4094cb268fa3",
            "19a4391701ad4399887e35757ed7eea6",
            "7b6d4a6e48be478a8f694bccbdfaa81d",
            "646ee18fffee4f0c89f23871c56223a8",
            "8cb3dd49227d4a72b4d7938444f0202a",
            "64f492d1096149ad9da667ea864d7f2b",
            "bc9c54b508ed4aabad64135937d16a70",
            "2053f4c66e57485a8e6176c4dbb68bd1",
            "7691a29d5bf44d01bafd6643400cbef0",
            "ba580709444348ac99daf82d488239a3",
            "5ddf722463404dbca2e1343722d2fe6b",
            "d4491208f1d641adbba7e3d9138aab5a",
            "8bbdbacf56ee44aca93e9a9a7ea824e0",
            "711cce8380d8411181387e51b7da25bb",
            "bf8df483688b4650bb5279a23602a520",
            "dbe917ae193a4c3c8cbcc9254dd8f639",
            "e47ec19a85da4dbaab999b5bb6490c05",
            "2e3a568ae6714c4aab97b67c7db2eb07"
          ]
        },
        "id": "2Hsmbn4QliGx",
        "outputId": "c3e97638-4673-4b67-f802-812d5c959544"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bb85d79994bd4000b514078fbc74587a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#Load the model and tokenizer\n",
        "model = AutoModelForCausalLM.from_pretrained(CONFIG.model_name, use_cache=False)\n",
        "tokenizer = CONFIG.tokenizer\n",
        "\n",
        "# Setting pad token to eos token\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
        "\n",
        "# Resize token embeddings\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "# Update model configuration\n",
        "model.config.pad_token_id = tokenizer.pad_token_id\n",
        "model.config.end_token_id = tokenizer.eos_token_id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_BfUJkMliGx"
      },
      "source": [
        "### Define Compute metric function (2.5 Points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNRBB004liGx"
      },
      "source": [
        "In this part, you should implement an evaluation function that computes rouge scores for our predicted summaries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "oAUXiZIzliGx"
      },
      "outputs": [],
      "source": [
        "# Load the ROUGE metric\n",
        "rouge = evaluate.load(\"rouge\")\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "    preds, labels = eval_preds\n",
        "    decoded_preds = [tokenizer.decode(pred, skip_special_tokens=True, clean_up_tokenization_spaces=True) for pred in preds]\n",
        "    decoded_labels = [tokenizer.decode(label, skip_special_tokens=True, clean_up_tokenization_spaces=True) for label in labels]\n",
        "    result = rouge.compute(predictions=decoded_preds, references=decoded_labels)\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "4PN_qjWOliGy"
      },
      "outputs": [],
      "source": [
        "# Create a preprocessing function to extract out the proper logits from the model output\n",
        "def preprocess_logits_for_metrics(logits, labels):\n",
        "    if isinstance(logits, tuple):\n",
        "        logits = logits[0]\n",
        "    return logits.argmax(dim=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6lnAyR4liGy"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "TPpjeWjqliGy"
      },
      "outputs": [],
      "source": [
        "# Set up training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=CONFIG.output_dir,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=250,\n",
        "    save_steps=500,\n",
        "    eval_accumulation_steps=1,\n",
        "    learning_rate=CONFIG.learning_rate,\n",
        "    per_device_train_batch_size=32, # I increased the batch_size\n",
        "    per_device_eval_batch_size=32,\n",
        "    gradient_checkpointing=True,\n",
        "    fp16=True,\n",
        "    fp16_backend=\"auto\",\n",
        "    adam_beta1=0.9,\n",
        "    adam_beta2=0.95,\n",
        "    num_train_epochs=4, # First I train the model for one epoch, then I train for four more apochs\n",
        "    warmup_steps=100,\n",
        "    load_best_model_at_end=True,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=500 #TODO\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "q4zCE76CliGy"
      },
      "outputs": [],
      "source": [
        "# Initialize the trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=dev_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    data_collator=default_data_collator,\n",
        "    preprocess_logits_for_metrics=preprocess_logits_for_metrics\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='752' max='752' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [752/752 37:12, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rouge1</th>\n",
              "      <th>Rouge2</th>\n",
              "      <th>Rougel</th>\n",
              "      <th>Rougelsum</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>1.898400</td>\n",
              "      <td>1.923292</td>\n",
              "      <td>0.582104</td>\n",
              "      <td>0.180484</td>\n",
              "      <td>0.381413</td>\n",
              "      <td>0.504274</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.875600</td>\n",
              "      <td>1.912207</td>\n",
              "      <td>0.586530</td>\n",
              "      <td>0.182838</td>\n",
              "      <td>0.383275</td>\n",
              "      <td>0.509494</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>1.843300</td>\n",
              "      <td>1.908619</td>\n",
              "      <td>0.586853</td>\n",
              "      <td>0.183296</td>\n",
              "      <td>0.384129</td>\n",
              "      <td>0.509715</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n"
          ]
        }
      ],
      "source": [
        "# Start training\n",
        "trainer.train()\n",
        "\n",
        "# Save the model\n",
        "trainer.save_model(CONFIG.output_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='268' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [63/63 04:36]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'eval_loss': 1.9122065305709839,\n",
              " 'eval_rouge1': 0.5865301790188278,\n",
              " 'eval_rouge2': 0.1828376831114582,\n",
              " 'eval_rougeL': 0.383274792047039,\n",
              " 'eval_rougeLsum': 0.509493881204031,\n",
              " 'eval_runtime': 128.17,\n",
              " 'eval_samples_per_second': 15.604,\n",
              " 'eval_steps_per_second': 0.492,\n",
              " 'epoch': 4.0}"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.evaluate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7UhxFCAwliGy"
      },
      "source": [
        "### Test (2.5 Points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVHkMLrMliGy"
      },
      "source": [
        "Report rouge scores for test set of TLDR dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_dataset = TLDRDataset(\n",
        "    path=tlrdataset_path,\n",
        "    tokenizer=CONFIG.tokenizer,\n",
        "    split=\"test\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test ROUGE scores:\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'eval_loss': 1.9079687595367432,\n",
              " 'eval_rouge1': 0.5875083782980206,\n",
              " 'eval_rouge2': 0.1831651352260253,\n",
              " 'eval_rougeL': 0.3838607240070928,\n",
              " 'eval_rougeLsum': 0.509185929201362,\n",
              " 'eval_runtime': 426.4569,\n",
              " 'eval_samples_per_second': 15.366,\n",
              " 'eval_steps_per_second': 0.481,\n",
              " 'epoch': 4.0}"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_results = trainer.evaluate(test_dataset)\n",
        "print(\"Test ROUGE scores:\")\n",
        "test_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLQOsyhCliGy"
      },
      "source": [
        "## Section Two: Reward Model Training (25 Points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWwhqfQdliGy"
      },
      "source": [
        "### Reward Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxD2B787liGy"
      },
      "source": [
        "We'll initialize the reward model from the SFT model and attach a randomly initialized linear head that outputs a scalar value on top.\n",
        "\n",
        "Next, we'll dig into how the data is input to the model, the loss function, and other gotchas of a reward model in more detail."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRdMjFNlliGy"
      },
      "source": [
        "### Question 1 (2.5 Points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzaalFlCliGy"
      },
      "source": [
        "**How would you create a comparison dataset for a text summarization task? (explain the entire procedure)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PgnAERZHliGy"
      },
      "source": [
        "This thask involves several key steps: data collection, preprocessing, initial summarization, human annotation, and dataset structuring. Hereâ€™s a detailed guide:\n",
        "\n",
        "**1. Data Collection**\n",
        "- Source Selection: Choose diverse sources like news articles, research papers, or blogs.\n",
        "- Data Gathering: Collect a substantial number of documents through web scraping, APIs, or open datasets.\n",
        "\n",
        "**2. Preprocessing**\n",
        "- Text Cleaning: Remove unwanted characters and normalize the text.\n",
        "- Segmentation: Break documents into smaller units if they are too long.\n",
        "\n",
        "**3. Initial Summarization**\n",
        "- Automatic Summarization: Use the model to generate initial summaries for each document.\n",
        "\n",
        "**4. Human Annotation**\n",
        "- Annotation Guidelines: Develop clear guidelines for comparing summaries on relevance, coherence, conciseness, readability, and accuracy.\n",
        "- Annotator Training: Train annotators to apply guidelines consistently.\n",
        "- Pairwise Comparison: Present annotators with pairs of summaries (e.g., machine vs. human-written) and ask them to rate or rank them.\n",
        "- Rating and Ranking: Collect ratings or rankings based on the provided guidelines.\n",
        "\n",
        "**5. Dataset Creation**\n",
        "- Include the document, summary pairs, and annotations. Ensure a balanced dataset with diverse examples.\n",
        "- Check for consistent and reliable annotations through cross-validation and reviews.\n",
        "\n",
        "**6. Post-processing**\n",
        "- Normalize scores or rankings for consistency.\n",
        "- Format the dataset to meet the requirements of your training framework.\n",
        "\n",
        "**7. Reward Model Integration**\n",
        "- Initialize Reward Model: Start with the supervised fine-tuned (SFT) summarization model.\n",
        "- Add a Linear Head: Attach a randomly initialized linear layer to the model that outputs a scalar value for scoring summaries.\n",
        "\n",
        "\n",
        "Creating a comparison dataset involves collecting and preprocessing data, generating initial summaries, obtaining human annotations through pairwise comparisons, structuring and formatting the dataset, and performing quality control. Finally, integrate the reward model by initializing it from the SFT model and adding a linear head for evaluation. This dataset and model setup are essential for training in a reinforcement learning from human feedback (RLHF) framework."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSf9CV6wliGy"
      },
      "source": [
        "### Question 2 (2.5 Points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D467FvoJliGy"
      },
      "source": [
        "**If you have 100 pairs of summaries, and for each pair one summary is prefered, how would you structurre your training data for the reward model?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JvmNLzCliG1"
      },
      "source": [
        "**Data Structure Definition**\n",
        "\n",
        "Each entry should include:\n",
        "* The document text.\n",
        "* The chosen summary.\n",
        "* The rejected summary.\n",
        "\n",
        "\n",
        "**Data Processing**\n",
        "\n",
        "Pairwise Data Extraction:\n",
        "* Extract pairs of summaries from the dataset.\n",
        "* Assign them to \"chosen\" and \"rejected\" based on the preference.\n",
        "\n",
        "\n",
        "```python\n",
        "# Assume we have a list of comparisons\n",
        "comparisons = [\n",
        "    {\n",
        "        \"prompt\": \"Full text of document 1\",\n",
        "        \"summary_1\": \"Generated summary 1\",\n",
        "        \"summary_2\": \"Generated summary 2\",\n",
        "        \"label\": 0 # Assign wich summary is prefered\n",
        "    },\n",
        "    {\n",
        "        \"prompt\": \"Full text of document 2\",\n",
        "        \"summary_1\": \"Generated summary 3\",\n",
        "        \"summary_2\": \"Generated summary 4\",\n",
        "        \"label\": 1 # Assign wich summary is non-prefered\n",
        "    }\n",
        "]\n",
        "\n",
        "# Prepare data for training\n",
        "train_data = []\n",
        "for comparison in comparisons:\n",
        "    document = comparison[\"prompt\"]\n",
        "    summary_1 = comparison[\"summary_1\"]\n",
        "    summary_2 = comparison[\"summary_2\"]\n",
        "    preferred_summary = comparison[\"label\"]\n",
        "    \n",
        "    if preferred_summary == 0:\n",
        "        train_data.append({\n",
        "            \"prompt\": document,\n",
        "            \"chosen\": summary_1,\n",
        "            \"rejected\": summary_2\n",
        "        })\n",
        "    else:\n",
        "        train_data.append({\n",
        "            \"prompt\": document,\n",
        "            \"chosen\": summary_2,\n",
        "            \"rejected\": summary_1\n",
        "        })\n",
        "\n",
        "```\n",
        "\n",
        "Finally we have this dataset:\n",
        "\n",
        "\n",
        "```json\n",
        "[\n",
        "    {\n",
        "        \"prompt\": \"Full text of document 1\",\n",
        "        \"chosen\": \"prefered summary\",\n",
        "        \"rejected\": \"non prefered summary\"\n",
        "    },\n",
        "    {\n",
        "        \"prompt\": \"Full text of document 2\",\n",
        "        \"chosen\": \"prefered summary\",\n",
        "        \"rejected\": \"non prefered summary\"\n",
        "    }\n",
        "]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2_7DbzzliG1"
      },
      "source": [
        "### Raw Input"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsTnuvmiliG1"
      },
      "source": [
        "Now, we'll create a list of dicts using the create_comparison_dataset function (shown below), where each dict has two keys - chosen and rejected. The value of each key is the prompt (or Reddit post) concatenated with the summary.\n",
        "\n",
        "**Note:** You can increase the number of training examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "yaBQ0g5EliG1"
      },
      "outputs": [],
      "source": [
        "def create_comparison_dataset(\n",
        "     path=\"CarperAI/openai_summarize_comparisons\", split=\"train\"\n",
        " ):\n",
        "     dataset = load_dataset(path, split=split)\n",
        "     if split == \"test\":\n",
        "         dataset = dataset.select(range(1000))\n",
        "     elif split == \"train\":\n",
        "         dataset = dataset.select(range(10000))\n",
        "\n",
        "     pairs = []\n",
        "     for sample in tqdm(dataset):\n",
        "         pair = {}\n",
        "         prompt = sample[\"prompt\"]\n",
        "         chosen_summary = sample[\"chosen\"]\n",
        "         rejected_summary = sample[\"rejected\"]\n",
        "         if chosen_summary == rejected_summary:\n",
        "             continue\n",
        "         if  len(chosen_summary.split()) < 5 or len(rejected_summary.split()) < 5:\n",
        "             continue\n",
        "         pair[\"chosen\"] = prompt + \"\\n\" + chosen_summary\n",
        "         pair[\"rejected\"] = prompt + \"\\n\" + rejected_summary\n",
        "         pairs.append(pair)\n",
        "     return pairs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfiEAWcUliG1"
      },
      "source": [
        "### Pairwise Dataloader (2.5 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtYfW4QYliG1"
      },
      "source": [
        "The PairwiseDataset class shown below tokenizes the chosen and rejected \"summaries\". The dataset class return the input_ids and attention_masks for both chosen and rejected summaries, in this part you should complete the **PairwiseDataset class.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "0emJGN1hliG1"
      },
      "outputs": [],
      "source": [
        "class PairwiseDataset(Dataset):\n",
        "    def __init__(self, pairs, tokenizer, max_length=512):\n",
        "        self.pairs = pairs\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.pairs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        pair = self.pairs[idx]\n",
        "\n",
        "        chosen_encodings = self.tokenizer(pair[\"chosen\"], truncation=True, max_length=self.max_length, padding=\"max_length\", return_tensors=\"pt\")\n",
        "        rejected_encodings = self.tokenizer(pair[\"rejected\"], truncation=True, max_length=self.max_length, padding=\"max_length\", return_tensors=\"pt\")\n",
        "\n",
        "        return [{\n",
        "            \"chosen_input_ids\": chosen_encodings[\"input_ids\"].squeeze(),\n",
        "            \"chosen_attention_mask\": chosen_encodings[\"attention_mask\"].squeeze(),\n",
        "            \"rejected_input_ids\": rejected_encodings[\"input_ids\"].squeeze(),\n",
        "            \"rejected_attention_mask\": rejected_encodings[\"attention_mask\"].squeeze()\n",
        "        }]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wy_jIkb5liG1"
      },
      "source": [
        "### Data Collator (2.5 Points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ueJlf6e9liG1"
      },
      "source": [
        "The DataCollatorReward class creates batches (dict) of data for our reward model. The collator returns:\n",
        "\n",
        "*   input_ids: collator concatenates the chosen and rejected summaries' input_ids across dim=0.\n",
        "*   attention_mask: collator concatenates the chosen and rejected summaries' attention_mask across dim=0.\n",
        "\n",
        "*   labels: collator creates a tensor of zeros for chosen summaries and a tensor of ones for rejected summaries concatenated across dim=0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "6XcjknZhliG2"
      },
      "outputs": [],
      "source": [
        "class DataCollatorReward:\n",
        "    def __call__(self, data):\n",
        "        batch = {}\n",
        "\n",
        "        chosen_input_ids = torch.stack([item[0][\"chosen_input_ids\"] for item in data])\n",
        "        rejected_input_ids = torch.stack([item[0][\"rejected_input_ids\"] for item in data])\n",
        "        \n",
        "        chosen_attention_mask = torch.stack([item[0][\"chosen_attention_mask\"] for item in data])\n",
        "        rejected_attention_mask = torch.stack([item[0][\"rejected_attention_mask\"] for item in data])\n",
        "        \n",
        "        # Concatenate chosen and rejected summaries\n",
        "        batch[\"input_ids\"] = torch.cat((chosen_input_ids, rejected_input_ids), dim=0)\n",
        "        batch[\"attention_mask\"] = torch.cat((chosen_attention_mask, rejected_attention_mask), dim=0)\n",
        "\n",
        "        # Create labels: 0 for chosen summaries, 1 for rejected summaries\n",
        "        chosen_labels = torch.zeros(chosen_input_ids.size(0), dtype=torch.long)\n",
        "        rejected_labels = torch.ones(rejected_input_ids.size(0), dtype=torch.long)\n",
        "        batch[\"labels\"] = torch.cat((chosen_labels, rejected_labels), dim=0)\n",
        "\n",
        "        return batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cF7h0HuHliG2"
      },
      "source": [
        "### What is happening in reward model?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zsVduq1liG2"
      },
      "source": [
        "Here, we have a Reddit post and two summaries (<font color='green'><b>chosen</b></font> and <font color='red'><b>rejected</b></font>) as input.\n",
        "\n",
        "The ground truth label (**labels**) is the human feedback (<font color='green'><b>0 for chosen</b></font> and <font color='red'><b>1 for rejected</b></font>). And the loss function (pairwise ranking loss) is given as:\n",
        "\n",
        "$$\\text{loss}(r_{\\theta}) = -\\mathbb{E}_{(x, y_0, y_1, i) \\sim D} \\left[ \\log \\left( \\sigma \\left( r_{\\theta}(x, y_i) - r_{\\theta}(x, y_{1-i}) \\right) \\right) \\right]\n",
        "$$.\n",
        "\n",
        "\n",
        "where:\n",
        "- $ x $ is the post,\n",
        "- $ y_0 $ and $ y_1 $ are the summaries,\n",
        "- $ i $ in {0, 1} indicates which summary is preferred by humans,\n",
        "- $ r_{\\theta}(x, y) $ is the reward model that returns a scalar value for the post $ x $ and the summary $ y $,\n",
        "- $ \\sigma $ is the sigmoid function.\n",
        "\n",
        "\n",
        "The reward model $ r_{\\theta} $ takes the post $ x $ and the summary $ y $ and returns a scalar value. The value is computed for both summaries and a sigmoid activation is applied to the difference.\n",
        "\n",
        "Finally, the negative log is computed.\n",
        "\n",
        "This loss function encourages the model to give higher scores to human-preferred summaries.\n",
        "\n",
        "**How to code this?**\n",
        "\n",
        "Our model receives input prepared by the data collator.\n",
        "\n",
        "*   This input is passed through the GPT-2 model to get the final hidden states.\n",
        "\n",
        "*   The hidden state is then passed through the linear layer to get a reward score.\n",
        "\n",
        "*   For each batch fed into the model, the first half is the chosen summaries, and the second half is the rejected summaries.\n",
        "\n",
        "*   The forward method of the model iterates through each input sample to compute pairwise loss.\n",
        "*  Return loss and chosen summaries scores and rejected summaries scores."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1M63SHQliG2"
      },
      "source": [
        "### Question 3 (2.5 Points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pU4AnDFjliG2"
      },
      "source": [
        "**What is the goal of pairwise ranking loss? and how we achieve this goal?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvQR7PGJliG2"
      },
      "source": [
        "**Goal of Pairwise Ranking Loss**\n",
        "\n",
        "The goal of the pairwise ranking loss in the context of training a reward model is to learn a scoring function $ r_{\\theta} $ that assigns higher scores to preferred outputs compared to less preferred outputs for the same input. In other words, the reward model should learn to rank the preferred (chosen) summaries higher than the rejected ones.\n",
        "\n",
        "**Achieving the Goal**\n",
        "\n",
        "To achieve this goal, the loss function operates as follows:\n",
        "\n",
        "1. **Score Calculation**:\n",
        "   - The reward model $ r_{\\theta} $ computes scores for both the chosen summary $ y_0 $ and the rejected summary $ y_1 $.\n",
        "\n",
        "2. **Score Difference**:\n",
        "   - Calculate the difference in scores: $ r_{\\theta}(x, y_i) - r_{\\theta}(x, y_{1-i}) $. Here, $ y_i $ is the preferred summary, and $ y_{1-i} $ is the less preferred one.\n",
        "\n",
        "3. **Sigmoid Function**:\n",
        "   - Apply the sigmoid function to this difference. The sigmoid function $ \\sigma(z) $ maps the difference to a probability range (0, 1), representing the <ins>likelihood</ins> that the chosen summary $ y_i $ is better than the rejected summary $y_{1-i}$.\n",
        "\n",
        "4. **Log Probability**:\n",
        "   - Take the logarithm of this probability. The log probability penalizes the model more heavily for being confident but wrong.\n",
        "\n",
        "5. **Expectation**:\n",
        "   - The expectation $ \\mathbb{E}_{(x, y_0, y_1, i) \\sim D} $ is taken over all pairs in the dataset, aiming to minimize this expected loss.\n",
        "\n",
        "Now, For each input $x$:\n",
        "1. We generate scores for both chosen and rejected summaries using the reward model.\n",
        "2. Compute the pairwise ranking loss using the formula.\n",
        "3. Backpropagate the loss and update the model parameters $\\theta$ to minimize the loss.\n",
        "\n",
        "=> minimizing the $loss$ => assigns higher scores to preferred outputs and lower scores to non-preferred for the same input."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vONyXMTzliG2"
      },
      "source": [
        "### Question 4 (2.5 Points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WtZsAmOliG2"
      },
      "source": [
        "**Explain that in the process of training the reward model, how the pairwise ranking loss can avoid the problem of huge score difference between the answers (summaries) and why is this useful?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7acT3rHRliG2"
      },
      "source": [
        "**Avoiding Huge Score Differences:**\n",
        "\n",
        "**1. Sigmoid Function**\n",
        "\n",
        "The sigmoid function $ \\sigma(z) = \\frac{1}{1 + e^{-z}} $ maps the input $ z $ to a value between 0 and 1. This function has a property where:\n",
        "- Small differences between $ r_{\\theta}(x, y_i) $ and $ r_{\\theta}(x, y_{1-i}) $ produce values close to 0.5.\n",
        "- Large positive differences produce values close to 1.\n",
        "- Large negative differences produce values close to 0.\n",
        "\n",
        "**2. Log Probability**\n",
        "\n",
        "Taking the logarithm of the sigmoid output further stabilizes the learning process. The logarithm function compresses the range of values, ensuring that extremely confident predictions (whether correct or incorrect) do not dominate the loss computation excessively. This avoids scenarios where huge score differences could lead to very large or very small gradient updates, which could destabilize training.\n",
        "\n",
        "**Why This Is Useful:**\n",
        "\n",
        "**1. Stable Training**\n",
        "\n",
        "Without this bounding, the gradients could become too large or too small, leading to issues like exploding or vanishing gradients. This stability allows the model to learn more effectively across iterations.\n",
        "\n",
        "**2. Focus on Relative Differences**\n",
        "\n",
        "The pairwise ranking loss focuses on the relative ranking of the chosen and rejected summaries rather than their absolute scores. This is particularly useful because:\n",
        "- It aligns with the goal of ranking preferred summaries higher, regardless of the actual score magnitudes.\n",
        "- It allows the model to learn from the ranking order rather than being affected by absolute score values, which can vary widely.\n",
        "\n",
        "**3. Robustness to Outliers**\n",
        "\n",
        "Outliers or extremely different summaries can skew the training process if absolute score differences are used directly. By focusing on the relative difference and using the sigmoid function, the model becomes more robust to such outliers, preventing them from disproportionately influencing the training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NioLnLEZliG2"
      },
      "source": [
        "### Implementing The Reward Model (5 Points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "GdyikVCTliG2"
      },
      "outputs": [],
      "source": [
        "class GPTRewardModel(nn.Module):\n",
        "    def __init__(self, model_path, model=None):\n",
        "        super().__init__()\n",
        "        if model is not None:\n",
        "            self.model = model\n",
        "        else:\n",
        "            self.model = AutoModelForCausalLM.from_pretrained(model_path)\n",
        "        self.config = self.model.config\n",
        "        self.linear = nn.Linear(self.config.hidden_size, 1)\n",
        "        self.loss_fn = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None, labels=None):\n",
        "        outputs = self.model(input_ids=input_ids, attention_mask=attention_mask, output_hidden_states=True)\n",
        "        print(f'Outputs logits: {outputs.logits.shape}')\n",
        "        print(f'Outputs hid.state: {len(outputs.hidden_states)}')\n",
        "        print(f'Outputs hid.state: {outputs.hidden_states[-1].shape}')\n",
        "        hidden_states = outputs.hidden_states[-1]  # Get the last hidden state\n",
        "        mean_hidden_state = hidden_states.mean(dim=1)  # Average over the sequence length\n",
        "        reward = self.linear(mean_hidden_state).squeeze(-1)\n",
        "\n",
        "        if labels is not None:\n",
        "            loss = self.loss_fn(reward, labels.float())\n",
        "            return loss, reward\n",
        "\n",
        "        return reward\n",
        "\n",
        "    def save_pretrained(self, save_directory):\n",
        "        self.model.save_pretrained(save_directory)\n",
        "        torch.save(self.linear.state_dict(), f\"{save_directory}/linear_layer.bin\")\n",
        "\n",
        "    @classmethod\n",
        "    def from_pretrained(cls, load_directory):\n",
        "        model_path = load_directory\n",
        "        model = cls(model_path)\n",
        "        model.model = AutoModelForCausalLM.from_pretrained(load_directory)\n",
        "        model.linear.load_state_dict(torch.load(f\"{load_directory}/linear_layer.bin\"))\n",
        "        return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOd4qInaliG2"
      },
      "source": [
        "**After finishing the above code, could you please explain how the scores for the selected summaries and the scores for the rejected summaries are calculated in your code?** (2.5 Points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYfEbDKVliG2"
      },
      "source": [
        "The reward model uses the GPT model's capability to transform input texts into meaningful embeddings, averages these embeddings or use the hidden state of first token, and then applies a linear transformation to arrive at a scalar score.\n",
        "\n",
        "This score is intended to reflect the quality or preference of the summary relative to other summaries, based on the training it received. The procedure is identical for both chosen and rejected summaries; what differs is the nature of the text input (i.e., whether the text is from a chosen or rejected summary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIJxF3SrliG3"
      },
      "source": [
        "### Load datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "PbcvI9_sliG3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/10000 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10000/10000 [00:00<00:00, 44713.92it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:00<00:00, 44155.22it/s]\n"
          ]
        }
      ],
      "source": [
        "# Create the comparisons datasets\n",
        "data_path = comparissions_path\n",
        "train_pairs = create_comparison_dataset(data_path, \"train\")\n",
        "val_pairs = create_comparison_dataset(data_path, \"test\")\n",
        "\n",
        "# Make pairwise datasets for training\n",
        "max_length = 550\n",
        "train_dataset = PairwiseDataset(train_pairs, tokenizer, max_length=max_length)\n",
        "val_dataset = PairwiseDataset(val_pairs, tokenizer, max_length=max_length)\n",
        "\n",
        "# Create the collator to gather batches of pairwise comparisons\n",
        "data_collator = DataCollatorReward()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhWhVCwHliG3"
      },
      "source": [
        "### Load Model and Tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAgDrdE5liG3"
      },
      "source": [
        "Initialize the reward model from the SFT GPT-2 model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "6ifGgccvliG3"
      },
      "outputs": [],
      "source": [
        "model = GPTRewardModel(CONFIG.output_dir)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(CONFIG.model_name)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# Freeze the first 70% of the hidden layers of the reward model backbone\n",
        "layers = model.model.transformer.h\n",
        "num_layers = len(layers)\n",
        "num_unfrozen = int(0.3 * num_layers)\n",
        "for layer in layers[:-num_unfrozen]:\n",
        "  layer.requires_grad_(False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTmCQxLaliG3"
      },
      "source": [
        "### Define Compute metric function (2.5 Points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOZSHkSMliG3"
      },
      "source": [
        "In this part you should implement the accuracy of our GPTRewardModel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "oMvztXmlliG3"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(eval_preds):\n",
        "    predictions = eval_preds.predictions\n",
        "    batch_size = predictions.shape[0] // 2\n",
        "    \n",
        "    chosen_rewards = predictions[:batch_size]\n",
        "    rejected_rewards = predictions[batch_size:]\n",
        "    \n",
        "    correct_predictions = (chosen_rewards > rejected_rewards).sum().item()\n",
        "    total_predictions = batch_size\n",
        "    \n",
        "    accuracy = correct_predictions / total_predictions\n",
        "    \n",
        "    return {\"accuracy\": accuracy}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lVSVRJcliG3"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "USnIpmXdliG3"
      },
      "outputs": [],
      "source": [
        "    training_args = TrainingArguments(\n",
        "      output_dir=\"rm_checkpoint/\",\n",
        "      num_train_epochs=1,\n",
        "      logging_steps=5,\n",
        "      gradient_accumulation_steps=4,\n",
        "      save_strategy=\"steps\",\n",
        "      evaluation_strategy=\"steps\",\n",
        "      per_device_train_batch_size=1,\n",
        "      per_device_eval_batch_size=1,\n",
        "      eval_accumulation_steps=1,\n",
        "      eval_steps=1,\n",
        "      save_steps=1,\n",
        "      warmup_steps=100,\n",
        "      logging_dir=\"./logs\",\n",
        "      fp16=True,\n",
        "      bf16=False,\n",
        "      learning_rate=1e-5,\n",
        "      save_total_limit=1,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "nhju2_0wliG3"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        compute_metrics=compute_metrics,\n",
        "        eval_dataset=val_dataset,\n",
        "        data_collator=data_collator,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n",
            "Outputs logits: torch.Size([2, 550, 50257])\n",
            "Outputs hid.state: 13\n",
            "Outputs hid.state: torch.Size([2, 550, 768])\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "\n            Some tensors share memory, this will lead to duplicate memory on disk and potential differences when loading them again: [{'model.lm_head.weight', 'model.transformer.wte.weight'}].\n            A potential way to correctly save your model is to use `save_model`.\n            More information at https://huggingface.co/docs/safetensors/torch_shared_tensors\n            ",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[61], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# trainer.save_model(CONFIG.output_dir_rm)\u001b[39;00m\n",
            "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/trainer.py:1885\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1883\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1884\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1885\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/trainer.py:2291\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2288\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mepoch \u001b[38;5;241m=\u001b[39m epoch \u001b[38;5;241m+\u001b[39m (step \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m steps_skipped) \u001b[38;5;241m/\u001b[39m steps_in_epoch\n\u001b[1;32m   2289\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m-> 2291\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2292\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2293\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_substep_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n",
            "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/trainer.py:2732\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2729\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mstep(metrics[metric_to_check])\n\u001b[1;32m   2731\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_save:\n\u001b[0;32m-> 2732\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2733\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_save(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n",
            "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/trainer.py:2811\u001b[0m, in \u001b[0;36mTrainer._save_checkpoint\u001b[0;34m(self, model, trial, metrics)\u001b[0m\n\u001b[1;32m   2809\u001b[0m run_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_output_dir(trial\u001b[38;5;241m=\u001b[39mtrial)\n\u001b[1;32m   2810\u001b[0m output_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(run_dir, checkpoint_folder)\n\u001b[0;32m-> 2811\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_internal_call\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   2813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39msave_only_model:\n\u001b[1;32m   2814\u001b[0m     \u001b[38;5;66;03m# Save optimizer and scheduler\u001b[39;00m\n\u001b[1;32m   2815\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_optimizer_and_scheduler(output_dir)\n",
            "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/trainer.py:3355\u001b[0m, in \u001b[0;36mTrainer.save_model\u001b[0;34m(self, output_dir, _internal_call)\u001b[0m\n\u001b[1;32m   3352\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_wrapped\u001b[38;5;241m.\u001b[39msave_checkpoint(output_dir)\n\u001b[1;32m   3354\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mshould_save:\n\u001b[0;32m-> 3355\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3357\u001b[0m \u001b[38;5;66;03m# Push to the Hub when `save_model` is called by the user.\u001b[39;00m\n\u001b[1;32m   3358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpush_to_hub \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _internal_call:\n",
            "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/trainer.py:3426\u001b[0m, in \u001b[0;36mTrainer._save\u001b[0;34m(self, output_dir, state_dict)\u001b[0m\n\u001b[1;32m   3424\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrainer.model is not a `PreTrainedModel`, only saving its state dict.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   3425\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39msave_safetensors:\n\u001b[0;32m-> 3426\u001b[0m     \u001b[43msafetensors\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3427\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSAFE_WEIGHTS_NAME\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mformat\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[1;32m   3428\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3429\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3430\u001b[0m     torch\u001b[38;5;241m.\u001b[39msave(state_dict, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_dir, WEIGHTS_NAME))\n",
            "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/safetensors/torch.py:284\u001b[0m, in \u001b[0;36msave_file\u001b[0;34m(tensors, filename, metadata)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave_file\u001b[39m(\n\u001b[1;32m    254\u001b[0m     tensors: Dict[\u001b[38;5;28mstr\u001b[39m, torch\u001b[38;5;241m.\u001b[39mTensor],\n\u001b[1;32m    255\u001b[0m     filename: Union[\u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike],\n\u001b[1;32m    256\u001b[0m     metadata: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    257\u001b[0m ):\n\u001b[1;32m    258\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;124;03m    Saves a dictionary of tensors into raw bytes in safetensors format.\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 284\u001b[0m     serialize_file(\u001b[43m_flatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m, filename, metadata\u001b[38;5;241m=\u001b[39mmetadata)\n",
            "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/safetensors/torch.py:480\u001b[0m, in \u001b[0;36m_flatten\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    477\u001b[0m         failing\u001b[38;5;241m.\u001b[39mappend(names)\n\u001b[1;32m    479\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m failing:\n\u001b[0;32m--> 480\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    481\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;124m        Some tensors share memory, this will lead to duplicate memory on disk and potential differences when loading them again: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfailing\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\n\u001b[1;32m    483\u001b[0m \u001b[38;5;124m        A potential way to correctly save your model is to use `save_model`.\u001b[39m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;124m        More information at https://huggingface.co/docs/safetensors/torch_shared_tensors\u001b[39m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;124m        \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m    486\u001b[0m     )\n\u001b[1;32m    488\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m    489\u001b[0m     k: {\n\u001b[1;32m    490\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(v\u001b[38;5;241m.\u001b[39mdtype)\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    494\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m tensors\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    495\u001b[0m }\n",
            "\u001b[0;31mRuntimeError\u001b[0m: \n            Some tensors share memory, this will lead to duplicate memory on disk and potential differences when loading them again: [{'model.lm_head.weight', 'model.transformer.wte.weight'}].\n            A potential way to correctly save your model is to use `save_model`.\n            More information at https://huggingface.co/docs/safetensors/torch_shared_tensors\n            "
          ]
        }
      ],
      "source": [
        "trainer.train()\n",
        "# trainer.save_model(CONFIG.output_dir_rm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "kck74cNUliG3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='501' max='1560' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 501/1560 24:34 < 52:08, 0.34 it/s, Epoch 1.60/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.692100</td>\n",
              "      <td>0.679815</td>\n",
              "      <td>0.515030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.684300</td>\n",
              "      <td>0.676564</td>\n",
              "      <td>0.523046</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "RuntimeError",
          "evalue": "\n            Some tensors share memory, this will lead to duplicate memory on disk and potential differences when loading them again: [{'model.transformer.wte.weight', 'model.lm_head.weight'}].\n            A potential way to correctly save your model is to use `save_model`.\n            More information at https://huggingface.co/docs/safetensors/torch_shared_tensors\n            ",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m trainer\u001b[38;5;241m.\u001b[39msave_model(CONFIG\u001b[38;5;241m.\u001b[39moutput_dir_rm)\n",
            "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/trainer.py:1885\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1883\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1884\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1885\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/trainer.py:2291\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2288\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mepoch \u001b[38;5;241m=\u001b[39m epoch \u001b[38;5;241m+\u001b[39m (step \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m steps_skipped) \u001b[38;5;241m/\u001b[39m steps_in_epoch\n\u001b[1;32m   2289\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m-> 2291\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2292\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2293\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_substep_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n",
            "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/trainer.py:2732\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2729\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mstep(metrics[metric_to_check])\n\u001b[1;32m   2731\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_save:\n\u001b[0;32m-> 2732\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2733\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_save(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n",
            "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/trainer.py:2811\u001b[0m, in \u001b[0;36mTrainer._save_checkpoint\u001b[0;34m(self, model, trial, metrics)\u001b[0m\n\u001b[1;32m   2809\u001b[0m run_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_output_dir(trial\u001b[38;5;241m=\u001b[39mtrial)\n\u001b[1;32m   2810\u001b[0m output_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(run_dir, checkpoint_folder)\n\u001b[0;32m-> 2811\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_internal_call\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   2813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39msave_only_model:\n\u001b[1;32m   2814\u001b[0m     \u001b[38;5;66;03m# Save optimizer and scheduler\u001b[39;00m\n\u001b[1;32m   2815\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_optimizer_and_scheduler(output_dir)\n",
            "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/trainer.py:3355\u001b[0m, in \u001b[0;36mTrainer.save_model\u001b[0;34m(self, output_dir, _internal_call)\u001b[0m\n\u001b[1;32m   3352\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_wrapped\u001b[38;5;241m.\u001b[39msave_checkpoint(output_dir)\n\u001b[1;32m   3354\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mshould_save:\n\u001b[0;32m-> 3355\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3357\u001b[0m \u001b[38;5;66;03m# Push to the Hub when `save_model` is called by the user.\u001b[39;00m\n\u001b[1;32m   3358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpush_to_hub \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _internal_call:\n",
            "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/trainer.py:3426\u001b[0m, in \u001b[0;36mTrainer._save\u001b[0;34m(self, output_dir, state_dict)\u001b[0m\n\u001b[1;32m   3424\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrainer.model is not a `PreTrainedModel`, only saving its state dict.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   3425\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39msave_safetensors:\n\u001b[0;32m-> 3426\u001b[0m     \u001b[43msafetensors\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3427\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSAFE_WEIGHTS_NAME\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mformat\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[1;32m   3428\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3429\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3430\u001b[0m     torch\u001b[38;5;241m.\u001b[39msave(state_dict, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_dir, WEIGHTS_NAME))\n",
            "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/safetensors/torch.py:284\u001b[0m, in \u001b[0;36msave_file\u001b[0;34m(tensors, filename, metadata)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave_file\u001b[39m(\n\u001b[1;32m    254\u001b[0m     tensors: Dict[\u001b[38;5;28mstr\u001b[39m, torch\u001b[38;5;241m.\u001b[39mTensor],\n\u001b[1;32m    255\u001b[0m     filename: Union[\u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike],\n\u001b[1;32m    256\u001b[0m     metadata: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    257\u001b[0m ):\n\u001b[1;32m    258\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;124;03m    Saves a dictionary of tensors into raw bytes in safetensors format.\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 284\u001b[0m     serialize_file(\u001b[43m_flatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m, filename, metadata\u001b[38;5;241m=\u001b[39mmetadata)\n",
            "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/safetensors/torch.py:480\u001b[0m, in \u001b[0;36m_flatten\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    477\u001b[0m         failing\u001b[38;5;241m.\u001b[39mappend(names)\n\u001b[1;32m    479\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m failing:\n\u001b[0;32m--> 480\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    481\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;124m        Some tensors share memory, this will lead to duplicate memory on disk and potential differences when loading them again: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfailing\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\n\u001b[1;32m    483\u001b[0m \u001b[38;5;124m        A potential way to correctly save your model is to use `save_model`.\u001b[39m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;124m        More information at https://huggingface.co/docs/safetensors/torch_shared_tensors\u001b[39m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;124m        \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m    486\u001b[0m     )\n\u001b[1;32m    488\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m    489\u001b[0m     k: {\n\u001b[1;32m    490\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(v\u001b[38;5;241m.\u001b[39mdtype)\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    494\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m tensors\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    495\u001b[0m }\n",
            "\u001b[0;31mRuntimeError\u001b[0m: \n            Some tensors share memory, this will lead to duplicate memory on disk and potential differences when loading them again: [{'model.transformer.wte.weight', 'model.lm_head.weight'}].\n            A potential way to correctly save your model is to use `save_model`.\n            More information at https://huggingface.co/docs/safetensors/torch_shared_tensors\n            "
          ]
        }
      ],
      "source": [
        "trainer.train()\n",
        "trainer.save_model(CONFIG.output_dir_rm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10000/10000 [00:00<00:00, 30642.15it/s]\n"
          ]
        },
        {
          "ename": "KeyError",
          "evalue": "'chosen_input_ids'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[76], line 54\u001b[0m\n\u001b[1;32m     43\u001b[0m reward_model \u001b[38;5;241m=\u001b[39m GPTRewardModel(model_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     45\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     46\u001b[0m     model\u001b[38;5;241m=\u001b[39mreward_model,\n\u001b[1;32m     47\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     51\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics\n\u001b[1;32m     52\u001b[0m )\n\u001b[0;32m---> 54\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/trainer.py:1885\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1883\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1884\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1885\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/trainer.py:2178\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2175\u001b[0m     rng_to_sync \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   2177\u001b[0m step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 2178\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, inputs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(epoch_iterator):\n\u001b[1;32m   2179\u001b[0m     total_batched_samples \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2181\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39minclude_num_input_tokens_seen:\n",
            "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/accelerate/data_loader.py:454\u001b[0m, in \u001b[0;36mDataLoaderShard.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;66;03m# We iterate one batch ahead to check when we are at the end\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 454\u001b[0m     current_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n",
            "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
            "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
            "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/trainer_utils.py:809\u001b[0m, in \u001b[0;36mRemoveColumnsCollator.__call__\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m    807\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, features: List[\u001b[38;5;28mdict\u001b[39m]):\n\u001b[1;32m    808\u001b[0m     features \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_remove_columns(feature) \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m features]\n\u001b[0;32m--> 809\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_collator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[42], line 5\u001b[0m, in \u001b[0;36mDataCollatorReward.__call__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data):\n\u001b[1;32m      3\u001b[0m     batch \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m----> 5\u001b[0m     chosen_input_ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([item[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchosen_input_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m data])\n\u001b[1;32m      6\u001b[0m     rejected_input_ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([item[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrejected_input_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m data])\n\u001b[1;32m      8\u001b[0m     chosen_attention_mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([item[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchosen_attention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m data])\n",
            "Cell \u001b[0;32mIn[42], line 5\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data):\n\u001b[1;32m      3\u001b[0m     batch \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m----> 5\u001b[0m     chosen_input_ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([\u001b[43mitem\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mchosen_input_ids\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m data])\n\u001b[1;32m      6\u001b[0m     rejected_input_ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([item[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrejected_input_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m data])\n\u001b[1;32m      8\u001b[0m     chosen_attention_mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([item[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchosen_attention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m data])\n",
            "\u001b[0;31mKeyError\u001b[0m: 'chosen_input_ids'"
          ]
        }
      ],
      "source": [
        "# Assuming pairs is your data and tokenizer is initialized\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
        "pairs = create_comparison_dataset()  # Your function to create pairs\n",
        "\n",
        "dataset = PairwiseDataset(pairs, tokenizer, max_length=512)\n",
        "data_collator = DataCollatorReward()\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "data_loader = DataLoader(dataset, batch_size=16, collate_fn=data_collator)\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "    predictions = eval_preds.predictions\n",
        "    batch_size = predictions.shape[0] // 2\n",
        "    \n",
        "    chosen_rewards = predictions[:batch_size]\n",
        "    rejected_rewards = predictions[batch_size:]\n",
        "    \n",
        "    correct_predictions = (chosen_rewards > rejected_rewards).sum().item()\n",
        "    total_predictions = batch_size\n",
        "    \n",
        "    accuracy = correct_predictions / total_predictions\n",
        "    \n",
        "    return {\"accuracy\": accuracy}\n",
        "\n",
        "\n",
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy=\"epoch\"\n",
        ")\n",
        "\n",
        "reward_model = GPTRewardModel(model_path=\"gpt2\")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=reward_model,\n",
        "    args=training_args,\n",
        "    train_dataset=dataset,\n",
        "    eval_dataset=dataset,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8X8eRJDliG3"
      },
      "source": [
        "## Section Three: PPO Fine Tuning (25 Points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odye-6kMliG3"
      },
      "source": [
        "### Question 5 (2.5 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nznG1XPUliG3"
      },
      "source": [
        "**What is PPO algorithm? and how it works?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwnofdGaliG3"
      },
      "source": [
        "\\# WRITE YOUR ANSWER HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbN18nGpliG3"
      },
      "source": [
        "### Question 6 (2.5 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "051cbYOHliG3"
      },
      "source": [
        "**Is the PPO algorithm an on-policy or off-policy reinforcement learning algorithm? Explain its functionality within our context (RLHF).**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnNg_n7wliG3"
      },
      "source": [
        "\\# WRITE YOUR ANSWER HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qf52CnPNliG3"
      },
      "source": [
        "### Question 7 (2.5 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7ULCFnCliG3"
      },
      "source": [
        "**Imagine a mini-batch of data has arrived, and we want to optimize the policy of generating summaries to maximize the reward using gradient ascent.**\n",
        "\n",
        "**Why shouldn't this policy change too much and, in other words, become overoptimized? (Answer based on the respond you provided to the previous question.)**\n",
        "\n",
        "**What do they do to solve this problem?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRntFnNyliG4"
      },
      "source": [
        "\\# WRITE YOUR ANSWER HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqXq1dD1liG4"
      },
      "source": [
        "### Question 8 (2.5 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9DxQa18liG4"
      },
      "source": [
        "**What is the overestimation problem in the ppo fine-tuning? and why it happens?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTB67tQfliG4"
      },
      "source": [
        "\\# WRITE YOUR ANSWER HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yspjLgeVliG4"
      },
      "source": [
        "### Question 9 (2.5 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66q19irOliG4"
      },
      "source": [
        "**What potential issue could arise when aligning a language model with human values? What solution has been proposed to address this issue?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UMTxiDdliG4"
      },
      "source": [
        "\\# WRITE YOUR ANSWER HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5oFLh6auliG4"
      },
      "source": [
        "### Question 10 (2.5 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppgwgfp7liG4"
      },
      "source": [
        "**We know that the objective function of the ppo tuning is as follows:**\n",
        "\n",
        "$$ \\text{objective}(\\phi) = \\mathbb{E}_{(x,y) \\sim D_{\\pi_{\\phi}^{\\text{RL}}}} \\left[ r_{\\theta}(x, y) - \\beta \\log \\left( \\frac{\\pi_{\\phi}^{\\text{RL}}(y \\mid x)}{\\pi^{\\text{SFT}}(y \\mid x)} \\right) \\right] + \\gamma \\mathbb{E}_{x \\sim D_{\\text{pretrain}}} \\left[ \\log(\\pi_{\\phi}^{\\text{RL}}(x)) \\right]\n",
        " $$\n",
        "\n",
        "**In the above objective function, the differentiation is with respect to $Î¦$, yet the term $r_{\\theta}(x, y)$ appears in the function.**\n",
        "\n",
        "**Explain why $r$ appears in the objective function despite being a function of $\\theta$ and why its derivative is not zero.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MszsZK-fliG4"
      },
      "source": [
        "\\# WRITE YOUR ANSWER HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJgxRLkDliG4"
      },
      "source": [
        "### Question 11 (5 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnkwyraDliG4"
      },
      "source": [
        "**Another term present in the objective function is $\\beta \\log \\left( \\frac{\\pi_{\\phi}^{\\text{RL}}(y \\mid x)}{\\pi^{\\text{SFT}}(y \\mid x)} \\right)$, which is the KLD between the initial policy distribution and the policy being learned. Explain why this term cannot be calculated directly.**\n",
        "\n",
        "\n",
        "**For a detailed explanation of how the KLD is calculated in this context, please read this <br>[blog post](http://joschu.net/blog/kl-approx.html). Afterward, provide an explanation of the calculation process.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bn9aDtEtliG4"
      },
      "source": [
        "\\# WRITE YOUR ANSWER HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8h1VdPVJliG4"
      },
      "source": [
        "### Question 12 (5 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yVF745CliG4"
      },
      "source": [
        "**How does DPO improve fine tuning?**\n",
        "\n",
        "**In DPO, our loss optimizing function to optimize for the policy is:**\n",
        "$$\\text{LDPO}(\\pi_\\theta; \\pi_\\text{ref}) = -\\mathbb{E}_{(x,y_w,y_l) \\sim D}\n",
        "\\left[\n",
        "\\log \\sigma\n",
        "\\left(\n",
        "\\beta \\log \\frac{\\pi_\\theta(y_w | x)}{\\pi_\\text{ref}(y_w | x)}\n",
        "- \\beta \\log \\frac{\\pi_\\theta(y_l | x)}{\\pi_\\text{ref}(y_l | x)}\n",
        "\\right)\n",
        "\\right]$$\n",
        "\n",
        "**Please explain the terms of this loss function and interpret the function.**\n",
        "\n",
        "\n",
        "**Now, please calculate the gradient of this loss function and Intuitively explain each term in the gradient of loss function.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OsGwADFOliG4"
      },
      "source": [
        "\\# WRITE YOUR ANSWER HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgMiQEouliG4"
      },
      "source": [
        "### Run PPO Fine Tuning (optional)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNoIe9weliG4"
      },
      "source": [
        "Because of the limitations of Google Colab, If you have access to an extra  GPU you can run below code for ppo fine tuning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4MDEVHxGliG5"
      },
      "outputs": [],
      "source": [
        "%pip install -U git+https://github.com/CarperAI/trlx.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RgklnHR3liG5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from datasets import load_dataset\n",
        "from tqdm import tqdm\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "import trlx\n",
        "from trlx.data.configs import (\n",
        "    ModelConfig,\n",
        "    OptimizerConfig,\n",
        "    SchedulerConfig,\n",
        "    TokenizerConfig,\n",
        "    TrainConfig,\n",
        "    TRLConfig,\n",
        ")\n",
        "from trlx.models.modeling_ppo import PPOConfig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J5S_0bM9liG5"
      },
      "outputs": [],
      "source": [
        "config = TRLConfig(\n",
        "    train=TrainConfig(\n",
        "        seq_length=550,\n",
        "        epochs=50,\n",
        "        total_steps=100000,\n",
        "        batch_size=4,\n",
        "        checkpoint_interval=10000,\n",
        "        eval_interval=200,\n",
        "        pipeline=\"PromptPipeline\",\n",
        "        trainer=\"AcceleratePPOTrainer\",\n",
        "    ),\n",
        "    model=ModelConfig(\n",
        "        model_path=\"gpt2\",\n",
        "        num_layers_unfrozen=8,\n",
        "    ),\n",
        "    tokenizer=TokenizerConfig(\n",
        "        tokenizer_path=\"gpt2\",\n",
        "        truncation_side=\"right\",\n",
        "    ),\n",
        "    optimizer=OptimizerConfig(\n",
        "        name=\"adamw\",\n",
        "        kwargs={\n",
        "            \"lr\": 5.0e-6,\n",
        "            \"betas\": [0.9, 0.999],\n",
        "            \"eps\": 1.0e-8,\n",
        "            \"weight_decay\": 0.01,\n",
        "        },\n",
        "    ),\n",
        "    scheduler=SchedulerConfig(\n",
        "        name=\"cosine_annealing\",\n",
        "        kwargs={\n",
        "            \"T_max\": 100000,\n",
        "            \"eta_min\": 5.0e-6,\n",
        "        },\n",
        "    ),\n",
        "    method=PPOConfig(\n",
        "        name=\"PPOConfig\",\n",
        "        num_rollouts=128,\n",
        "        chunk_size=16,\n",
        "        ppo_epochs=4,\n",
        "        init_kl_coef=0.1,\n",
        "        target=6,\n",
        "        horizon=10000,\n",
        "        gamma=1,\n",
        "        lam=0.95,\n",
        "        cliprange=0.2,\n",
        "        cliprange_value=0.2,\n",
        "        vf_coef=0.2,\n",
        "        scale_reward=None,\n",
        "        ref_mean=None,\n",
        "        ref_std=None,\n",
        "        cliprange_reward=10,\n",
        "        gen_kwargs={\n",
        "            \"max_new_tokens\": 50,\n",
        "        },\n",
        "    ),\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7kDLLWSGliG5"
      },
      "outputs": [],
      "source": [
        "REWARD_CHECKPOINT_PATH = \"\"\n",
        "SFT_MODEL_PATH = \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O0e5L7T2liG5"
      },
      "outputs": [],
      "source": [
        "from typing import List\n",
        "def get_scores(samples: List[str]):\n",
        "  scores_list = []\n",
        "  batch_size = 2\n",
        "  for i in range(0, len(samples), batch_size):\n",
        "    sub_samples = samples[i : i + batch_size]\n",
        "    sub_samples = [\"<|startoftext|>\" + chosen + \"<|endoftext|>\" for chosen in sub_samples]\n",
        "    encodings_dict = rw_tokenizer(\n",
        "        sub_samples,\n",
        "        truncation=True,\n",
        "        max_length=config.train.seq_length,\n",
        "        padding=\"max_length\",\n",
        "        return_tensors=\"pt\",\n",
        "        )\n",
        "    input_ids = encodings_dict[\"input_ids\"].to(rw_device)\n",
        "    attn_masks = encodings_dict[\"attention_mask\"].to(rw_device)\n",
        "    input_ids = input_ids.repeat(2, 1)\n",
        "    attn_masks = attn_masks.repeat(2, 1)\n",
        "    with torch.no_grad():\n",
        "      sub_scores = rw_model(input_ids=input_ids, attention_mask=attn_masks)\n",
        "    scores_list.append(sub_scores[\"chosen_end_scores\"])\n",
        "  scores = torch.cat(scores_list, dim=0)\n",
        "  return scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4BeXGRuyliG5"
      },
      "outputs": [],
      "source": [
        "rw_tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "rw_tokenizer.pad_token = rw_tokenizer.eos_token\n",
        "rw_model = GPTRewardModel(SFT_MODEL_PATH)\n",
        "rw_model.load_state_dict(torch.load(REWARD_CHECKPOINT_PATH), strict=False)\n",
        "rw_model.half()\n",
        "rw_model.eval()\n",
        "rw_model.to(CONFIG.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lHL-Bs1eliG5"
      },
      "outputs": [],
      "source": [
        "def get_prompt_dataset(prompts, max_length):\n",
        "  formatted_prompts = []\n",
        "  for i in tqdm(range(len(prompts))):\n",
        "    tmp = tokenizer.decode(\n",
        "        tokenizer(\n",
        "              prompts[i].split(\"TL;DR:\")[0],\n",
        "              truncation=True,\n",
        "              max_length=max_length - 5,\n",
        "              add_special_tokens=False,\n",
        "            )[\"input_ids\"],\n",
        "            skip_special_tokens=True,\n",
        "            ).strip()\n",
        "    tmp = tmp + \"\\nTL;DR:\"\n",
        "    tmp = tokenizer.decode(\n",
        "          tokenizer(tmp, truncation=True, max_length=max_length, add_special_tokens=False)[\"input_ids\"],\n",
        "          skip_special_tokens=True,\n",
        "        ).strip()\n",
        "    formatted_prompts.append(tmp)\n",
        "  return formatted_prompts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D3NqMZu5liG5"
      },
      "outputs": [],
      "source": [
        "def reward_fn(samples: List[str], **kwargs):\n",
        "  original_samples = [text.split(\"TL;DR:\")[0] + \"TL;DR: \" for text in samples]\n",
        "  original_samples = [text + post_summary_dict[text.strip()] for text in original_samples]\n",
        "  original_scores = get_scores(original_samples)\n",
        "  scores = get_scores(samples)\n",
        "  norms_scores = scores - original_scores\n",
        "  return norms_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_a8fbDBuliG5"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(config.tokenizer.tokenizer_path)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"left\"\n",
        "max_length_input = config.train.seq_length - config.method.gen_kwargs[\"max_new_tokens\"]\n",
        "\n",
        "# Load the dataset\n",
        "dataset = load_dataset(\"carperai/openai_summarize_tldr\")\n",
        "\n",
        "# Get the total number of samples in the training dataset\n",
        "total_samples = len(dataset[\"train\"])\n",
        "\n",
        "# Generate random indices for selecting samples\n",
        "random_indices = random.sample(range(total_samples), 5000)\n",
        "\n",
        "# Select samples using random indices\n",
        "train_set = [(dataset[\"train\"][index][\"prompt\"], dataset[\"train\"][index][\"label\"]) for index in random_indices]\n",
        "val_set = [(sample[\"prompt\"], sample[\"label\"]) for sample in dataset[\"valid\"]]\n",
        "\n",
        "# Split contents into summaries and labels\n",
        "train_posts, train_summaries = zip(*train_set)\n",
        "val_posts, val_summaries = zip(*val_set)\n",
        "\n",
        "# Get the OpenAI summaries\n",
        "post_summary_dict = {}\n",
        "train_prompts = get_prompt_dataset(train_posts, max_length_input)\n",
        "for i in range(len(train_prompts)):\n",
        "  post_summary_dict[train_prompts[i]] = train_summaries[i]\n",
        "val_prompts = get_prompt_dataset(val_posts, max_length_input)\n",
        "for i in range(len(val_prompts)):\n",
        "  post_summary_dict[val_prompts[i]] = val_summaries[i]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GugzrPa_liG5"
      },
      "outputs": [],
      "source": [
        "trainer = trlx.train(\n",
        "    reward_fn=reward_fn,\n",
        "    prompts=train_prompts,\n",
        "    eval_prompts=val_prompts[0:1000],  # sampling 1000 validation prompts for evaluation speed in training\n",
        "    config=config,\n",
        "  )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBP-hkzEliG5"
      },
      "source": [
        "# Quantization (26 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jR4LIwnCliG5"
      },
      "source": [
        "Quantization is a technique used to reduce the precision of neural network weights and activations, typically from floating-point to a lower-bit representation, such as 8-bit or 4-bit integers. The primary goal of quantization is to reduce the memory footprint and computational requirements of deep learning models, enabling the loading of larger models that would normally not fit into available memory, and speeding up the inference process."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yX3IbcrVliG5"
      },
      "source": [
        "## A simple example (2 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtNa3uKRliG5"
      },
      "source": [
        "Let's see what happens when a we quantize a 32-bit floating-point number."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s1jaB5hsliG5"
      },
      "outputs": [],
      "source": [
        "# Import neccesary libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxo4FpTFliG5"
      },
      "source": [
        "Defining two functions which responsible for quantizing and dequantizing the input number:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N7t0v2RxliG6"
      },
      "outputs": [],
      "source": [
        "def quantize(value, num_bits=4):\n",
        "    quantized_value = np.round(value * (2**(num_bits - 1) - 1))\n",
        "    return int(quantized_value)\n",
        "\n",
        "def dequantize(quantized_value, num_bits=4):\n",
        "    value = quantized_value / (2**(num_bits - 1) - 1)\n",
        "    return float(value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kuf-64O5liG6"
      },
      "source": [
        "Consider the value `0.326`, the quantized values in 4 and 8 bits are:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bOQ-MJETliG6"
      },
      "outputs": [],
      "source": [
        "q_4bit = quantize(value=0.326, num_bits=4)\n",
        "q_8bit = quantize(value=0.326, num_bits=8)\n",
        "\n",
        "print(f'4-bit: {q_4bit}')\n",
        "print(f'8-bit: {q_8bit}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSFVYdbFliG6"
      },
      "source": [
        "And if we dequantize it to original full precision values we would have:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cXgpYWgyliG6"
      },
      "outputs": [],
      "source": [
        "print(f'4-bit: {dequantize(quantized_value=q_4bit, num_bits=4)}')\n",
        "print(f'8-bit: {dequantize(quantized_value=q_8bit, num_bits=8)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62EqHz2FliG6"
      },
      "source": [
        "8-bit quantization preserves the original precision with very little degradationa and 4-bit quantization does incur more precision loss, but the level of loss can still be tolerated for many applications."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKjkbccyliG6"
      },
      "source": [
        "To understand the precision loss from 4-bit and 8-bit quantization, plot the function $y = x^2$ in the range of $[-1, 1]$, and compare the original values to the values obtained after quantization and dequantization for both 4-bit and 8-bit cases. (2 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s0BMw9LzliG6"
      },
      "outputs": [],
      "source": [
        "# WRITE YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ASecpj7liG6"
      },
      "source": [
        "## QLoRA: Efficient Finetuning of Quantized LLMs (24 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Akr6OhtWliG6"
      },
      "source": [
        "Now, it's time to see the magic of quantization. We are going to fine-tune Mistral 7B model based on the method proposed by [QLoRA: Efficient Finetuning of Quantized LLMs](https://arxiv.org/abs/2305.14314)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Az1kOYjOliG6"
      },
      "source": [
        "### Prerequisite"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARgU36wzliG6"
      },
      "source": [
        "Installing and importing libraries which we will need later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ITqClfSxliG6"
      },
      "outputs": [],
      "source": [
        "!pip install -q accelerate==0.29.3\n",
        "!pip install -q bitsandbytes==0.43.1\n",
        "!pip install -q trl==0.8.6\n",
        "!pip install -q peft==0.10.0\n",
        "!pip install -q transformers==4.40.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DKvCF2-cliG6"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "from trl import SFTTrainer\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tNWeHkDliG6"
      },
      "source": [
        "### Hugging Face Login"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkpuugsVliG6"
      },
      "source": [
        "For some language models, you need to agree to share your contact information to access the model. Mistral 7B is one of them. The steps you should take are as follows:\n",
        "\n",
        "1.   Create a Gugging Face account if you don't have one.\n",
        "2.   From Settings > Access Tokens, generate a new token.\n",
        "3.   From [this link](https://huggingface.co/mistralai/Mistral-7B-v0.1) agree to access the repository.\n",
        "\n",
        "Now, run the code below to login to your account."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "25vTyCA-liG6"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import login\n",
        "access_token_read = # your api token here\n",
        "login(token = access_token_read)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lKc4I9vliG6"
      },
      "source": [
        "### The Model (6 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8C71CI8ZliG6"
      },
      "source": [
        "To load the model, first we need a quantization configuration to set how we want to quantize the model. We are going to use `BitsAndBytesConfig` to achieve our goal. `BitsAndBytesConfig` is the easiest option for quantizing a model to 8 and 4-bit.\n",
        "\n",
        "Define the quantization configuration in the cell below based on the fact that we are looking for 4-bit quantization. Also, QLoRA paper proposed two techniques: 4-bit NormalFloat(NF4) quantization and Double Quantization. Set these two setup in our configuration too. To speedup the computation try to set computational type as bf16. (2 points)\n",
        "\n",
        "Try to explain what is the Double Quantization technique. You can use the provided paper to read about it. (4 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmKYvFTlliG6"
      },
      "source": [
        "\\# WRITE YOUR ANSWER HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LiU0JmvkliG6"
      },
      "outputs": [],
      "source": [
        "model_name = 'mistralai/Mistral-7B-v0.1'\n",
        "\n",
        "quantization_config = # WRITE YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JB6GGQ9wliG7"
      },
      "source": [
        "Now, let's load the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CMg4--m2liG7"
      },
      "outputs": [],
      "source": [
        "device_map = {\"\": 0}\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name,\n",
        "                    quantization_config=quantization_config,\n",
        "                    device_map=device_map,\n",
        "                    use_cache = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgoxRNz4liG7"
      },
      "source": [
        "Now, we have the quantized model on the memory. You can try to load the model without quantization into memory to see if it is possible."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9f-h69h3liG7"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "tokenizer.pad_token = tokenizer.eos_token"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufcvIS94liG7"
      },
      "source": [
        "### Generate text using the pre-trained model (1 point)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HoJK7uzliG7"
      },
      "source": [
        "In this part we are going to test the pre-trained model to see its capabilities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "USJG6n_JliG7"
      },
      "outputs": [],
      "source": [
        "# Function which generate outputs corresponding to input prompts\n",
        "def generate_output(model, inputs, max_length=50):\n",
        "\n",
        "    tokenized_inputs = tokenizer(inputs, padding=True, return_tensors=\"pt\").to('cuda')\n",
        "    output = model.generate(\n",
        "        input_ids=tokenized_inputs[\"input_ids\"],\n",
        "        attention_mask=tokenized_inputs[\"attention_mask\"],\n",
        "        max_new_tokens=max_length,\n",
        "        repetition_penalty=1.5,\n",
        "        early_stopping=False,\n",
        "        eos_token_id=tokenizer.eos_token_id,\n",
        "    )\n",
        "\n",
        "    text = tokenizer.batch_decode(output, skip_special_tokens=True)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-4aZeJ0liG7"
      },
      "source": [
        "Using the `generate_output` function try to produce output of the pre-trained model for the following prompts: (1 point)\n",
        "\n",
        "* \"What's up?\"\n",
        "* 'Hello, How are you?'\n",
        "* 'hello, Can you help me?'\n",
        "* 'what is the capital of France?'\n",
        "* 'Hi! what do you do for a living?'\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZzmwARwNliG7"
      },
      "outputs": [],
      "source": [
        "# WRITE YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rf0dg5nBliG7"
      },
      "source": [
        "### The Dataset (4 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUiem55MliG7"
      },
      "source": [
        "We loaded a 7B LLM into the memory and succeeded to inference from the model. Now, using [this dataset](https://huggingface.co/datasets/SAGI-1/Greetings_DPO_dataset_V1) we want to fine-tune our pre-trained model.\n",
        "\n",
        "After loading the dataset, choose 75 samples of it. We would like to backpropagate only the tokens of the completion and not the prompt itself. In order to do this, use `DataCollatorForCompletionOnlyLM` (check the examples provided in [this link](https://huggingface.co/docs/trl/en/sft_trainer#train-on-completions-only)). Also, you can ignore the `rejected` column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gHdqOVuFliG7"
      },
      "outputs": [],
      "source": [
        "# WRITE YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGmRA7I7liG7"
      },
      "source": [
        "### Fine-tuning (8 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBXpgSDZliG7"
      },
      "source": [
        "We want to fine-tune the model with the help of [LoRA](https://arxiv.org/abs/2106.09685). Try to create a LoRA configuration with rank and alpha parameter both equal to 12. (3 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KNa8fk8MliG7"
      },
      "outputs": [],
      "source": [
        "import peft\n",
        "from peft import LoraConfig, get_peft_model\n",
        "\n",
        "target_modules = [\"q_proj\", \"v_proj\"]\n",
        "lora_config = # WRITE YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gR92T3V1liG7"
      },
      "source": [
        "We are going to use SFTtrainer from trl library. In order to work within memory constraints, try to set the batch size and the number of update steps to accumulate the gradients equal to 1. Also, don't forget to enable the `gradient_checkpointing`. (5 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WxteG8s_liG7"
      },
      "outputs": [],
      "source": [
        "# WRITE YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bP3XIco2liG7"
      },
      "source": [
        "### Check the fine-tuned model (5 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtRCMb9ZliG7"
      },
      "source": [
        "Try to check the fine-tuned model on the five aformentioned prompts which we test earlier. Compare you results of fine-tuned and pre-trained model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTdXI7GaliG7"
      },
      "source": [
        "\\# WRITE YOUR ANSWER HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RTz-Gm0dliG7"
      },
      "outputs": [],
      "source": [
        "# WRITE YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XcU69fllliG8"
      },
      "source": [
        "In case you have memory problem try `del` statement for the variables you don't need. The code below also could be beneficial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GVJw7WZ6liG8"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54Wa42NtliG8"
      },
      "source": [
        "# Instruct Tuning (4 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6DIF-4qNliG8"
      },
      "source": [
        "What we done earlier was somehow instruct tuning in which we fine-tune the pre-trained model to follow the instructions.However, with 75 samples we can't do anything big. As you probably know, the pre-training objective for auto-regressive models is to simply predict the next word. Therefore, they are not optimized to answer to your prompts, rather they try continue the text you provided.\n",
        "\n",
        "In many practical settings (like chatbots) we need the model to follow the instructions provided by the user. So, huge datasets consisting of prompts and their corresponding answer are used to fine-tune these models for interactive use cases.\n",
        "\n",
        "Using the quantization technique we used earlier try to load the quantized version of [Mistral-7B-Instruct](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1) which have been optimized for following the instructions. Check the five samples we used earlier and compare your results.\n",
        "\n",
        "Try to check the provided link to see how you should format the prompt to leverage instruction fine-tuning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "04HY3MbuliG8"
      },
      "outputs": [],
      "source": [
        "instruct_model = 'mistralai/Mistral-7B-Instruct-v0.1'\n",
        "# WRITE YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enKlQTAVliG8"
      },
      "source": [
        "\\# WRITE YOUR ANSWER HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbVo3DQQliG8"
      },
      "source": [
        "# Evaluation (25 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvIAojNGliG8"
      },
      "source": [
        "## Evaluating text using a language model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjIBCESmliG8"
      },
      "source": [
        "One way of evaluating text generation is by using a language model.\n",
        "In this assignment, we want to use BERTScore to compare the similarity of sentences.\n",
        "After reading [BERTScore paper](https://arxiv.org/abs/1904.09675) answer the following questions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zux9coTYliG8"
      },
      "source": [
        "### 1)\n",
        "How does BERTScore evaluate semantic equivalence and how is it better than n-gram based metrics like BLEU? (5 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZ_O4mjnliG8"
      },
      "source": [
        "\\# WRITE YOUR ANSWER HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQA5q_fWliG8"
      },
      "source": [
        "### 2)\n",
        "Implement BERTScore recall $R_{BERT}$ in the paper. You don't need to bother with the Importance Weighting. We use a more modern model called deberta which is better than bert in many ways. Then visualize similarity matrix. You can use the visualization code given to you. (7 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HqIkNBZrliG8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-v3-small\")\n",
        "model = AutoModel.from_pretrained(\"microsoft/deberta-v3-small\")\n",
        "\n",
        "def cosine_similarity(a, b):\n",
        "    return # WRITE YOUR CODE HERE (implement using pytorch CosineSimilarity)\n",
        "\n",
        "def bert_score(reference, candidate):\n",
        "\n",
        "\n",
        "    # WRITE YOUR CODE HERE (Tokenize the input text)\n",
        "    ref_tokens = \"tokenize reference sentence\"\n",
        "    candidate_tokens = \"you should know what to do here\"\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # WRITE YOUR CODE HERE (get the embeddings please)\n",
        "        pass\n",
        "\n",
        "\n",
        "    similarities = \"The similarities matrix\"\n",
        "\n",
        "    R_BERT = \"\"\"You can see max in the BERTScore formula in the paper. Then what are you waiting for? Implement the thing.\n",
        "            Pay attention to the fact that you are computing recall. It's important to be careful about\n",
        "              which axis you are getting the max on.\"\"\"\n",
        "    bertscore = R_BERT.mean()\n",
        "\n",
        "\n",
        "    return bertscore, similarities\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AMHYsxrJliG8"
      },
      "outputs": [],
      "source": [
        "reference = \"Cats are cute\"\n",
        "candidate = \"Cats are annoying\"\n",
        "\n",
        "bertscore, sim_matrix = bert_score(\n",
        "    reference, candidate)\n",
        "\n",
        "print(bertscore)\n",
        "print(sim_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PFt2JSZFliG8"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def heatmap(\n",
        "    matrix,\n",
        "    hide_spines=False,\n",
        "    hide_ticks=False,\n",
        "    figsize=None,\n",
        "    cmap=None,\n",
        "    colorbar=True,\n",
        "    row_names=None,\n",
        "    column_names=None,\n",
        "    column_name_rotation=45,\n",
        "    cell_values=True,\n",
        "    cell_fmt=\".2f\",\n",
        "    cell_font_size=None,\n",
        "):\n",
        "\n",
        "    if row_names is not None and len(row_names) != matrix.shape[0]:\n",
        "        raise AssertionError(\n",
        "            f\"len(row_names) (got {len(row_names)})\"\n",
        "            \" should be equal to number of\"\n",
        "            \" rows in the input \"\n",
        "            f\" array (expect {matrix.shape[0]}).\"\n",
        "        )\n",
        "\n",
        "    if column_names is not None and len(column_names) != matrix.shape[1]:\n",
        "        raise AssertionError(\n",
        "            f\"len(column_names)\"\n",
        "            \" (got {len(column_names)})\"\n",
        "            \" should be equal to number of\"\n",
        "            \" columns in the\"\n",
        "            f\" input array (expect {matrix.shape[1]}).\"\n",
        "        )\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=figsize)\n",
        "    ax.grid(False)\n",
        "\n",
        "    if cmap is None:\n",
        "        cmap = plt.cm.viridis\n",
        "\n",
        "    if figsize is None:\n",
        "        figsize = (len(matrix) * 1.5, len(matrix) * 1.5)\n",
        "\n",
        "    matshow = ax.matshow(matrix, cmap=cmap)\n",
        "\n",
        "    if colorbar:\n",
        "        fig.colorbar(matshow)\n",
        "\n",
        "    normed_matrix = matrix.astype(\"float\") / matrix.max()\n",
        "\n",
        "    if cell_values:\n",
        "        for i in range(matrix.shape[0]):\n",
        "            for j in range(matrix.shape[1]):\n",
        "                cell_text = format(matrix[i, j], cell_fmt)\n",
        "\n",
        "                ax.text(\n",
        "                    x=j,\n",
        "                    y=i,\n",
        "                    size=cell_font_size,\n",
        "                    s=cell_text,\n",
        "                    va=\"center\",\n",
        "                    ha=\"center\",\n",
        "                    color=\"black\"\n",
        "                    if normed_matrix[i, j] > np.max(normed_matrix) / 2\n",
        "                    else \"black\",\n",
        "                )\n",
        "\n",
        "    if row_names is not None:\n",
        "        tick_marks = np.arange(len(row_names))\n",
        "        plt.yticks(tick_marks, row_names)\n",
        "\n",
        "    if column_names is not None:\n",
        "        tick_marks = np.arange(len(column_names))\n",
        "\n",
        "        if column_name_rotation:\n",
        "            plt.xticks(\n",
        "                tick_marks,\n",
        "                column_names,\n",
        "                rotation=column_name_rotation,\n",
        "                ha=\"right\",\n",
        "                rotation_mode=\"anchor\",\n",
        "            )\n",
        "        else:\n",
        "            plt.xticks(tick_marks, column_names)\n",
        "\n",
        "    if hide_spines:\n",
        "        ax.spines[\"right\"].set_visible(False)\n",
        "        ax.spines[\"top\"].set_visible(False)\n",
        "        ax.spines[\"left\"].set_visible(False)\n",
        "        ax.spines[\"bottom\"].set_visible(False)\n",
        "    ax.yaxis.set_ticks_position(\"left\")\n",
        "    ax.xaxis.set_ticks_position(\"bottom\")\n",
        "    if hide_ticks:\n",
        "        ax.axes.get_yaxis().set_ticks([])\n",
        "        ax.axes.get_xaxis().set_ticks([])\n",
        "\n",
        "    return fig, ax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N4STcfpIliG8"
      },
      "outputs": [],
      "source": [
        "from matplotlib import cm\n",
        "from matplotlib.colors import ListedColormap\n",
        "\n",
        "viridisBig = cm.get_cmap('Blues', 512)\n",
        "newcmp = ListedColormap(viridisBig(np.linspace(0.0, 0.5, 256)))\n",
        "\n",
        "fig, ax = heatmap(sim_matrix, column_names=reference.split(), row_names=candidate.split(), cmap=newcmp, figsize=(4, 4))\n",
        "\n",
        "plt.tight_layout();\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7e0wMXpTliG8"
      },
      "source": [
        "### 3)\n",
        "Using the [Official BERTScore](https://github.com/Tiiiger/bert_score) package. Compare your implementation with the official one and tell us why they differ. (3 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pJQNnr5uliG9"
      },
      "outputs": [],
      "source": [
        "# pip install bert-score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v0Sf7hGTliG9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from bert_score import score\n",
        "\n",
        "reference = \"Cats are cute\"\n",
        "candidate = \"Cats are annoying\"\n",
        "\n",
        "P, R, F1 = score(\n",
        "    # WRITE YOUR CODE HERE (complete yourself)\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaAYAIieliG9"
      },
      "source": [
        "### 4)\n",
        "Download datasets \"sst2\" and \"imdb\" from huggingface datasets. Both of these datasets are for the same task but their distribution differs. In what ways their distribution differ according to [this paper](https://aclanthology.org/2021.emnlp-main.835/)?\n",
        "\n",
        "randomly choose ten sentences from negative and ten sentences from positive labels of each dataset (forty sentences in total)\n",
        "\n",
        "use your implementation of BERTScore and compute similarity of\n",
        "\n",
        "a) sentences that are in the same dataset and have same label and take average\n",
        "\n",
        "b) sentences that are in the same dataset and have opposite label and take average\n",
        "\n",
        "c) sentences that are in different datasets and have same label and take average\n",
        "\n",
        "d) sentences that are in the different dataset and have opposite label and take average\n",
        "\n",
        "How these numbers differ and why? (for example for part a you should put each sentence as reference once and compare it with ten candidate sentences including itself, after doing this for all ten sentences you get a hundred scores and then an average.) (10 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQ5_XWVWliG9"
      },
      "source": [
        "\\# WRITE YOUR ANSWER HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# AI Assistant"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* How to create a comparison dataset for a text summarization task for reward model in RLHF?\n",
        "* What is the goal of the pairwise ranking loss in the context of training a reward model?\n",
        "* How the pairwise ranking loss can avoid the problem of huge score difference between the answers (summaries) during training and why is this useful?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "005b8f782bdb4ab2a8a5e40a75674d96": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04588e43dc174ae5bcebc0ef01d581dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58cabc7c155747fc8cbe2f27f1beb289",
            "max": 26,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cce757f48382449da0d3e3bf87272284",
            "value": 26
          }
        },
        "054c5f4fc64744a7a46e991855c7b386": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d18ab3331f1a42f1af89aca50b9e78e6",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_08a9f29c73b54e0cbc89738191edb1a8",
            "value": "config.json:â€‡100%"
          }
        },
        "08a9f29c73b54e0cbc89738191edb1a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0b831cc698eb4838960af0add2becea1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0e017c1b69fe4e89b3a5e169c9387445": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0faf1d3472974ceca6eeda7e9d5f7906": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c6c5a944a23e456ebb6c69805e4d4e2e",
            "max": 532,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_196db38e52bf47e0a529d725ad71d007",
            "value": 532
          }
        },
        "12ce1164d18249b3807e5ec45aac4a84": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16f10c9d3be140829e228ad4b3aa7705": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "18439c99c16d4162b8a2a52d86dc5847": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "196db38e52bf47e0a529d725ad71d007": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "19a4391701ad4399887e35757ed7eea6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1dd9d180974942d89cabcc4d318a6cf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f99bdeb99dc43f882494cb9a8d1f664": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2053f4c66e57485a8e6176c4dbb68bd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7691a29d5bf44d01bafd6643400cbef0",
              "IPY_MODEL_ba580709444348ac99daf82d488239a3",
              "IPY_MODEL_5ddf722463404dbca2e1343722d2fe6b"
            ],
            "layout": "IPY_MODEL_d4491208f1d641adbba7e3d9138aab5a"
          }
        },
        "236c712f6f234e3f8d7f4ea00feb7f6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8bd37b87fba4f8a9e2d0e9bb80a13f0",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_748e4fce751841348c8907d56a01d2a1",
            "value": 1042301
          }
        },
        "2510e83f724343019d01a35a84e76bf9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27fa70cf544147f29b2a8a17c4f2faa3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64f492d1096149ad9da667ea864d7f2b",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_bc9c54b508ed4aabad64135937d16a70",
            "value": "â€‡548M/548Mâ€‡[00:07&lt;00:00,â€‡25.0MB/s]"
          }
        },
        "29201ca978c5470aa05877d0ace36f31": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2923856e65fd40718b7358bfbb3143cf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29c0f9d47313413386f284f7393211d1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2bb6760048f24cb59f6ff5f16b3c7acd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c3ffd876324474594f95fe1c71d3782": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2e3a568ae6714c4aab97b67c7db2eb07": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2e3fa17580e544aaa238a07cdeb116b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af5827003e7c43d8b6bda1efceeb1fae",
            "max": 1355256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5d82735ec2df45c7b9fd820df07d938d",
            "value": 1355256
          }
        },
        "30ae280e5d5b462daa1f61b929e51a3e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "329fab4cb7a14053b47bdd56ad38ec60": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d839e15480684df99f1ce3a7c6c41342",
              "IPY_MODEL_774a79f0517a4d5c8b2a037f6a59dc3e",
              "IPY_MODEL_7b52f480da1e4554a39b731269dc5d28"
            ],
            "layout": "IPY_MODEL_96762776b2564b0ca0eda807d998d097"
          }
        },
        "334a2eeec579455ba662deabd578f29d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3451ffe86a4a4d7a8858e4e720789857": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "38b91d003fc541908101453b9655abb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6ba35709a0f4221bff3209b66f6ccde",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_64f0e8ad62e448f9b767515e44bf4e9b",
            "value": "â€‡116722/116722â€‡[00:04&lt;00:00,â€‡17225.77â€‡examples/s]"
          }
        },
        "39e1e4fa159044ea97c5f9c78ba14a1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "40465bc3852f40018eb5173d2a789c7f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41afb58c5a964028a4943def4b861b97": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41f16b59ab674b67ab1577adb413ae48": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44e178a0be524daa95b256d5bff31202": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_452cea6360ce498c85e843e348deb1f4",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_16f10c9d3be140829e228ad4b3aa7705",
            "value": "Downloadingâ€‡data:â€‡100%"
          }
        },
        "452cea6360ce498c85e843e348deb1f4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "458e2312cf2c47fea736fc230083a0de": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_83f9dbdfcf7443ce8589e0c59116afcf",
              "IPY_MODEL_9ed93d180d26497596cdeb3f8d014e09",
              "IPY_MODEL_9544135d58ee491191ea3b16bf2424eb"
            ],
            "layout": "IPY_MODEL_2510e83f724343019d01a35a84e76bf9"
          }
        },
        "45a46219b04b4d5989b5a7a241c165b5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4759413c86e845d9a8e374ee135ff414": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab0a3df7a8904389904bfcb31a148b7f",
            "max": 116722,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c692217a3ef84e04bccb3bcdd4a2ec8a",
            "value": 116722
          }
        },
        "4929031e60fa4ad883215fc9470113ae": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a452ec981ff415680f80c2cfd30a0ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4a9bad66b87348589618e074a6b2f747": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5cef8de414a447ff911632ff05beedfb",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_39e1e4fa159044ea97c5f9c78ba14a1c",
            "value": "Downloadingâ€‡data:â€‡100%"
          }
        },
        "4b02a2cb6fe14ccd9d85a86994c6cb67": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5243aeab7e624b02b273463fb32fbf42": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5446c6060f8e419ab8184d0e15981690": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a97ec2a948e549ae9d97c2ce6d8d962e",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_b2729e2fde2549d1b531e9320dd6649d",
            "value": "vocab.json:â€‡100%"
          }
        },
        "55634652e74049b199344e325dff5676": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "57be34f94b554f0e94f45635efd721b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7cf3fe343cdd45b291523b15dc8f4c1a",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_ac236fc0d5bc4d8f962e3d35b859893d",
            "value": "tokenizer_config.json:â€‡100%"
          }
        },
        "5835fb83bd014edcaedc1974e2738273": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "58cabc7c155747fc8cbe2f27f1beb289": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c38c56a72d74118a65c7eca2d47aaa0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5cef8de414a447ff911632ff05beedfb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d1aaf2a41fd47e1ba3a2a73855db66b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4a9bad66b87348589618e074a6b2f747",
              "IPY_MODEL_94712aabc9504ec7a3d204a914118b6c",
              "IPY_MODEL_70010175a0c9460c89a2297895f9425e"
            ],
            "layout": "IPY_MODEL_9cf51736a40e490ba9daa0aa4585d614"
          }
        },
        "5d82735ec2df45c7b9fd820df07d938d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5d88dfa6c6e04cc689bdc9f753fd26fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bb4c6b6b74824b6b8fcc74009aa36768",
              "IPY_MODEL_c6acfb70629745729fa440a02b5aa6f1",
              "IPY_MODEL_d4c3590ed00243a99495add140c2f504"
            ],
            "layout": "IPY_MODEL_4b02a2cb6fe14ccd9d85a86994c6cb67"
          }
        },
        "5dd2682ec2ab4a1ba0d0023ffe3cc4a9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ddf722463404dbca2e1343722d2fe6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e47ec19a85da4dbaab999b5bb6490c05",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_2e3a568ae6714c4aab97b67c7db2eb07",
            "value": "â€‡124/124â€‡[00:00&lt;00:00,â€‡7.33kB/s]"
          }
        },
        "5e9e490c3c244b09a1d8f9007a5d8717": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "646ee18fffee4f0c89f23871c56223a8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64f0e8ad62e448f9b767515e44bf4e9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "64f492d1096149ad9da667ea864d7f2b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e2efc4590694d2ab3e02f4baa2ed821": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70010175a0c9460c89a2297895f9425e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f61f3b244ab5421e8a2c18d37c33e290",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_920ac1c6300d4ac2b826fa0fcc1c4cd8",
            "value": "â€‡111M/111Mâ€‡[00:00&lt;00:00,â€‡171MB/s]"
          }
        },
        "711cce8380d8411181387e51b7da25bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7151d446f6964946af694275001a8b50": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "723a0a0fae6344b2bdc445d69af1517a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c16c6f1424134cb7ab354757b7ce2c15",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_0b831cc698eb4838960af0add2becea1",
            "value": "â€‡1.36M/1.36Mâ€‡[00:00&lt;00:00,â€‡37.9MB/s]"
          }
        },
        "748e4fce751841348c8907d56a01d2a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7691a29d5bf44d01bafd6643400cbef0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8bbdbacf56ee44aca93e9a9a7ea824e0",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_711cce8380d8411181387e51b7da25bb",
            "value": "generation_config.json:â€‡100%"
          }
        },
        "774a79f0517a4d5c8b2a037f6a59dc3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4929031e60fa4ad883215fc9470113ae",
            "max": 6553,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a6bc156f830b4829b35f298ed7d733bf",
            "value": 6553
          }
        },
        "7b52f480da1e4554a39b731269dc5d28": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e2efc4590694d2ab3e02f4baa2ed821",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_de83309c1bd54e66a613b755a89f4455",
            "value": "â€‡6553/6553â€‡[00:00&lt;00:00,â€‡66960.49â€‡examples/s]"
          }
        },
        "7b6d4a6e48be478a8f694bccbdfaa81d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7b770a26b25c449fbdac9824c6b00204": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8cc35a3254b049de9d1535e4c4a64dda",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_5835fb83bd014edcaedc1974e2738273",
            "value": "â€‡1.04M/1.04Mâ€‡[00:00&lt;00:00,â€‡12.0MB/s]"
          }
        },
        "7bcdb14ff8c64ff4b1d7b882a85f89dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_005b8f782bdb4ab2a8a5e40a75674d96",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_5c38c56a72d74118a65c7eca2d47aaa0",
            "value": "tokenizer.json:â€‡100%"
          }
        },
        "7cd8e757c96f4a4481c5fffd99fb2cf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c5541f7a0b3d405388df008eb820a130",
              "IPY_MODEL_ca480988b2404679954759cb9e2c991c",
              "IPY_MODEL_f73da3dc44384c7baad205eaa14bfb41"
            ],
            "layout": "IPY_MODEL_af155570f61742c181961e49703cf911"
          }
        },
        "7cf3fe343cdd45b291523b15dc8f4c1a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d3ece0ec61a4f7eb21808f759df7690": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83f9dbdfcf7443ce8589e0c59116afcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8cc0f0cf5d14e83b002ead2a0c3afa4",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_de3fe2d2e22547e1beb6c76b59d71082",
            "value": "Downloadingâ€‡data:â€‡100%"
          }
        },
        "8525e5dc75cb42d790ee5e59c96cee5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19a4391701ad4399887e35757ed7eea6",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_7b6d4a6e48be478a8f694bccbdfaa81d",
            "value": "model.safetensors:â€‡100%"
          }
        },
        "890cde66805f46b2bcc713df00dfbe22": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "896bed8372804158aa4bc944e6401f42": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41f16b59ab674b67ab1577adb413ae48",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_1dd9d180974942d89cabcc4d318a6cf0",
            "value": "â€‡665/665â€‡[00:00&lt;00:00,â€‡33.9kB/s]"
          }
        },
        "8bbdbacf56ee44aca93e9a9a7ea824e0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8cb3dd49227d4a72b4d7938444f0202a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8cc35a3254b049de9d1535e4c4a64dda": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d354fed57014964962451731bb319ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93c404b763094295aa1bbcdc5847e3b9",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_2c3ffd876324474594f95fe1c71d3782",
            "value": "Downloadingâ€‡readme:â€‡100%"
          }
        },
        "8ee845415acf4bb29a6a3fc5c2c72070": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "90066549c0b4446bbae7b2a16fbe1a6b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "920ac1c6300d4ac2b826fa0fcc1c4cd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "93c404b763094295aa1bbcdc5847e3b9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94712aabc9504ec7a3d204a914118b6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45a46219b04b4d5989b5a7a241c165b5",
            "max": 110623451,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a5c0c29181fc4821b4017e7028372431",
            "value": 110623451
          }
        },
        "9544135d58ee491191ea3b16bf2424eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90066549c0b4446bbae7b2a16fbe1a6b",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_18439c99c16d4162b8a2a52d86dc5847",
            "value": "â€‡6.23M/6.23Mâ€‡[00:00&lt;00:00,â€‡54.1MB/s]"
          }
        },
        "96762776b2564b0ca0eda807d998d097": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97816036a7c643feb7c24755f4e2233b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99d0e034709c40359095a9004cc46798": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b3cc7be38ab486abb29f68c4ec58388": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9cf51736a40e490ba9daa0aa4585d614": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ed93d180d26497596cdeb3f8d014e09": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1fe338ae4604838b403b255a4637154",
            "max": 6225522,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5243aeab7e624b02b273463fb32fbf42",
            "value": 6225522
          }
        },
        "a22888ab49b941bfae153b1d7d6a3fe9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_054c5f4fc64744a7a46e991855c7b386",
              "IPY_MODEL_caaca6163cff4afb9b28978b1e64065a",
              "IPY_MODEL_896bed8372804158aa4bc944e6401f42"
            ],
            "layout": "IPY_MODEL_40465bc3852f40018eb5173d2a789c7f"
          }
        },
        "a483b3f8216d4de88866cb1a017c14bb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4d54d72871743a68f60983a3bdbf55d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5c0c29181fc4821b4017e7028372431": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a6bc156f830b4829b35f298ed7d733bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a97ec2a948e549ae9d97c2ce6d8d962e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab0a3df7a8904389904bfcb31a148b7f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac236fc0d5bc4d8f962e3d35b859893d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ac756657854e4ec78993df53314cc18f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed16f76131904795900803fb1238f73d",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_334a2eeec579455ba662deabd578f29d",
            "value": "â€‡6.12M/6.12Mâ€‡[00:00&lt;00:00,â€‡60.9MB/s]"
          }
        },
        "af155570f61742c181961e49703cf911": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af5827003e7c43d8b6bda1efceeb1fae": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2729e2fde2549d1b531e9320dd6649d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b41bb97a0a7a4cd589d837144eed8200": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5446c6060f8e419ab8184d0e15981690",
              "IPY_MODEL_236c712f6f234e3f8d7f4ea00feb7f6a",
              "IPY_MODEL_7b770a26b25c449fbdac9824c6b00204"
            ],
            "layout": "IPY_MODEL_30ae280e5d5b462daa1f61b929e51a3e"
          }
        },
        "b54c45a49eb1484194a576d0421c0fe0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a483b3f8216d4de88866cb1a017c14bb",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_3451ffe86a4a4d7a8858e4e720789857",
            "value": "â€‡532/532â€‡[00:00&lt;00:00,â€‡14.7kB/s]"
          }
        },
        "b6fa7a2add97484cbea0c26ed46d29e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_44e178a0be524daa95b256d5bff31202",
              "IPY_MODEL_c33b7e89df304f78b3b498a8f9c68383",
              "IPY_MODEL_ac756657854e4ec78993df53314cc18f"
            ],
            "layout": "IPY_MODEL_2923856e65fd40718b7358bfbb3143cf"
          }
        },
        "ba580709444348ac99daf82d488239a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf8df483688b4650bb5279a23602a520",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dbe917ae193a4c3c8cbcc9254dd8f639",
            "value": 124
          }
        },
        "bb4c6b6b74824b6b8fcc74009aa36768": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4d54d72871743a68f60983a3bdbf55d",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_0e017c1b69fe4e89b3a5e169c9387445",
            "value": "Generatingâ€‡validâ€‡split:â€‡100%"
          }
        },
        "bc9c54b508ed4aabad64135937d16a70": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bd1e9d756633421e980ac84a1ed3df96": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99d0e034709c40359095a9004cc46798",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_e6953b8a8ace427ca7689f7fc6cfd6b3",
            "value": "â€‡26.0/26.0â€‡[00:00&lt;00:00,â€‡1.39kB/s]"
          }
        },
        "bda44f920ef0452991f345ffb8843f73": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf8df483688b4650bb5279a23602a520": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c16c6f1424134cb7ab354757b7ce2c15": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c33b7e89df304f78b3b498a8f9c68383": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bda44f920ef0452991f345ffb8843f73",
            "max": 6124527,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_890cde66805f46b2bcc713df00dfbe22",
            "value": 6124527
          }
        },
        "c5541f7a0b3d405388df008eb820a130": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b3cc7be38ab486abb29f68c4ec58388",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_5e9e490c3c244b09a1d8f9007a5d8717",
            "value": "merges.txt:â€‡100%"
          }
        },
        "c692217a3ef84e04bccb3bcdd4a2ec8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c6acfb70629745729fa440a02b5aa6f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5dd2682ec2ab4a1ba0d0023ffe3cc4a9",
            "max": 6447,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4a452ec981ff415680f80c2cfd30a0ad",
            "value": 6447
          }
        },
        "c6c5a944a23e456ebb6c69805e4d4e2e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8cc0f0cf5d14e83b002ead2a0c3afa4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca480988b2404679954759cb9e2c991c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97816036a7c643feb7c24755f4e2233b",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8ee845415acf4bb29a6a3fc5c2c72070",
            "value": 456318
          }
        },
        "caa2f6b29a0349aa80d773185181056b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8d354fed57014964962451731bb319ef",
              "IPY_MODEL_0faf1d3472974ceca6eeda7e9d5f7906",
              "IPY_MODEL_b54c45a49eb1484194a576d0421c0fe0"
            ],
            "layout": "IPY_MODEL_2bb6760048f24cb59f6ff5f16b3c7acd"
          }
        },
        "caaca6163cff4afb9b28978b1e64065a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12ce1164d18249b3807e5ec45aac4a84",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1f99bdeb99dc43f882494cb9a8d1f664",
            "value": 665
          }
        },
        "cce757f48382449da0d3e3bf87272284": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cf4a4ec0a7124457a68d70970889b744": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d18ab3331f1a42f1af89aca50b9e78e6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1fe338ae4604838b403b255a4637154": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3fccbdf94bc44cdb552e3ac37a54e0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ddcd794463174f51b09f6b77ab732b94",
              "IPY_MODEL_4759413c86e845d9a8e374ee135ff414",
              "IPY_MODEL_38b91d003fc541908101453b9655abb2"
            ],
            "layout": "IPY_MODEL_7d3ece0ec61a4f7eb21808f759df7690"
          }
        },
        "d4491208f1d641adbba7e3d9138aab5a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4c3590ed00243a99495add140c2f504": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e53325f28cab44a5ab6a9218764b45d2",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_d5f193695fde47e8b9edd4f84f2ecf2b",
            "value": "â€‡6447/6447â€‡[00:00&lt;00:00,â€‡74605.88â€‡examples/s]"
          }
        },
        "d5f193695fde47e8b9edd4f84f2ecf2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d6ba35709a0f4221bff3209b66f6ccde": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7554a7bb8bd4d5dbbc03268dc2d77c4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d839e15480684df99f1ce3a7c6c41342": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7554a7bb8bd4d5dbbc03268dc2d77c4",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_cf4a4ec0a7124457a68d70970889b744",
            "value": "Generatingâ€‡testâ€‡split:â€‡100%"
          }
        },
        "dbe917ae193a4c3c8cbcc9254dd8f639": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ddcd794463174f51b09f6b77ab732b94": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29201ca978c5470aa05877d0ace36f31",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_7151d446f6964946af694275001a8b50",
            "value": "Generatingâ€‡trainâ€‡split:â€‡100%"
          }
        },
        "de3fe2d2e22547e1beb6c76b59d71082": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "de83309c1bd54e66a613b755a89f4455": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dfc95e5b17b94e1dae5b0c5a26a9da5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7bcdb14ff8c64ff4b1d7b882a85f89dd",
              "IPY_MODEL_2e3fa17580e544aaa238a07cdeb116b7",
              "IPY_MODEL_723a0a0fae6344b2bdc445d69af1517a"
            ],
            "layout": "IPY_MODEL_29c0f9d47313413386f284f7393211d1"
          }
        },
        "e400bbe893d744b4bc4ec3c00d0ab49a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_57be34f94b554f0e94f45635efd721b7",
              "IPY_MODEL_04588e43dc174ae5bcebc0ef01d581dc",
              "IPY_MODEL_bd1e9d756633421e980ac84a1ed3df96"
            ],
            "layout": "IPY_MODEL_ed839cf80d8e4f4a8feaa109cd9202b6"
          }
        },
        "e47ec19a85da4dbaab999b5bb6490c05": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e53325f28cab44a5ab6a9218764b45d2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6953b8a8ace427ca7689f7fc6cfd6b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e8bd37b87fba4f8a9e2d0e9bb80a13f0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed16f76131904795900803fb1238f73d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed839cf80d8e4f4a8feaa109cd9202b6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f10cd68089cc4e3ebe9b774054517c80": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_646ee18fffee4f0c89f23871c56223a8",
            "max": 548105171,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8cb3dd49227d4a72b4d7938444f0202a",
            "value": 548105171
          }
        },
        "f61f3b244ab5421e8a2c18d37c33e290": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f73da3dc44384c7baad205eaa14bfb41": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41afb58c5a964028a4943def4b861b97",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_55634652e74049b199344e325dff5676",
            "value": "â€‡456k/456kâ€‡[00:00&lt;00:00,â€‡21.4MB/s]"
          }
        },
        "fe88b66639f64622adda4094cb268fa3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff6e07c2c9de408cb353b2b57ad52673": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8525e5dc75cb42d790ee5e59c96cee5f",
              "IPY_MODEL_f10cd68089cc4e3ebe9b774054517c80",
              "IPY_MODEL_27fa70cf544147f29b2a8a17c4f2faa3"
            ],
            "layout": "IPY_MODEL_fe88b66639f64622adda4094cb268fa3"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
